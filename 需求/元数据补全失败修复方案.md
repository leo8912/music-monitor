# 元数据补全失败修复方案

## 问题定位
经过分析确认，自动元数据补全失败的主要原因包括：
1. 24小时冷却期过长，导致失败后重试机会有限
2. 重试机制不够灵活，固定3次重试可能不足以应对网络波动
3. 搜索策略相对固定，缺乏针对失败案例的优化

## 具体修复措施

### 1. 冷却期策略优化

#### 修改冷却期计算逻辑
```python
def _in_cooldown(self, song: Song) -> bool:
    """检查是否在冷却期 - 优化版"""
    if not song.last_enrich_at:
        return False
    
    delta = datetime.now() - song.last_enrich_at
    hours_passed = delta.total_seconds() / 3600
    
    # 根据失败次数动态调整冷却期
    failure_count = getattr(song, 'enrich_failure_count', 0)
    
    if failure_count == 0:
        cooldown_hours = 1  # 首次失败：1小时冷却
    elif failure_count == 1:
        cooldown_hours = 3  # 第二次失败：3小时冷却
    elif failure_count <= 3:
        cooldown_hours = 6  # 第3-4次失败：6小时冷却
    else:
        cooldown_hours = 12  # 4次以上失败：12小时冷却
    
    return hours_passed < cooldown_hours
```

#### 增加失败计数跟踪
```python
async def heal_song(self, song_id: str, force: bool = False) -> bool:
    """治愈单首歌曲 - 增强版"""
    async with AsyncSessionLocal() as db:
        song = await db.get(Song, song_id, options=[selectinload(Song.artist), selectinload(Song.sources)])
        if not song: 
            return False

        # 初始化失败计数
        if not hasattr(song, 'enrich_failure_count'):
            song.enrich_failure_count = 0

        logger.info(f"🩹 正在治愈: {song.title} (失败次数: {song.enrich_failure_count})")

        try:
            # ... 现有治愈逻辑 ...
            
            # 成功时重置失败计数
            song.enrich_failure_count = 0
            song.last_enrich_at = datetime.now()
            await db.commit()
            return True
            
        except Exception as e:
            # 失败时增加计数
            song.enrich_failure_count += 1
            song.last_enrich_at = datetime.now()
            await db.commit()
            logger.warning(f"❌ 治愈失败 [{song.title}] (第{song.enrich_failure_count}次): {e}")
            return False
```

### 2. 重试机制增强

#### 增加重试次数和智能退避
```python
# 在 metadata_service.py 中修改重试装饰器
@async_retry(max_retries=5, backoff_factor=2)  # 5次重试，指数退避
async def fetch_metadata(self, title: str, artist: str, source: str = None, source_id: str = None) -> MetadataResult:
    # ... 现有逻辑 ...
```

#### 实现渐进式搜索策略
```python
async def get_best_match_metadata(self, title: str, artist: str) -> MetadataResult:
    """
    增强版最佳匹配元数据获取
    实现渐进式搜索策略
    """
    logger.info(f"🔍 增强搜索: {title} - {artist}")
    result = MetadataResult()
    
    # 搜索策略优先级
    search_strategies = [
        # 策略1：标准搜索（标题 + 艺人）
        lambda: self._standard_search(title, artist),
        
        # 策略2：纯标题搜索
        lambda: self._title_only_search(title),
        
        # 策略3：文件名解析搜索
        lambda: self._filename_search(title, artist),
        
        # 策略4：简化关键词搜索
        lambda: self._simplified_search(title, artist)
    ]
    
    for i, strategy in enumerate(search_strategies):
        try:
            strategy_result = await strategy()
            if strategy_result and strategy_result.success:
                logger.info(f"✅ 策略{i+1}成功: {title}")
                return strategy_result
            else:
                logger.info(f"⏭️ 策略{i+1}失败，尝试下一策略")
        except Exception as e:
            logger.warning(f"⚠️ 策略{i+1}异常: {e}")
            continue
    
    logger.warning(f"❌ 所有搜索策略均失败: {title} - {artist}")
    return result

async def _standard_search(self, title: str, artist: str) -> MetadataResult:
    """标准搜索：标题 + 艺人"""
    keyword = f"{title} {artist}".strip()
    return await self._perform_search(keyword)

async def _title_only_search(self, title: str) -> MetadataResult:
    """纯标题搜索"""
    return await self._perform_search(title)

async def _filename_search(self, title: str, artist: str) -> MetadataResult:
    """文件名解析搜索"""
    # 移除常见前缀和后缀
    clean_title = re.sub(r'^\d+[\.\-\s]*', '', title)  # 移除开头数字
    clean_title = re.sub(r'\s*\([^)]*\)', '', clean_title)  # 移除括号内容
    clean_title = re.sub(r'\s*\[[^\]]*\]', '', clean_title)  # 移除方括号内容
    return await self._perform_search(clean_title)

async def _simplified_search(self, title: str, artist: str) -> MetadataResult:
    """简化关键词搜索"""
    # 提取关键词的核心部分
    keywords = []
    if artist:
        keywords.append(artist.split()[0])  # 只取艺人的第一个词
    if title:
        # 取标题的前几个重要词汇
        title_words = title.split()
        keywords.extend(title_words[:3])  # 最多取前3个词
    
    simplified_keyword = " ".join(keywords)
    return await self._perform_search(simplified_keyword)

async def _perform_search(self, keyword: str) -> MetadataResult:
    """执行实际的搜索操作"""
    if not keyword.strip():
        return MetadataResult()
    
    logger.info(f"🔍 执行搜索: '{keyword}'")
    
    providers = [
        ("netease", self._get_netease_provider()),
        ("qqmusic", self._get_qqmusic_provider())
    ]
    
    # 并发搜索所有源
    async def search_provider(source_name: str, provider):
        if not provider:
            return source_name, None
        try:
            search_results = await provider.search_song(keyword, limit=5)
            if search_results:
                best_match = search_results[0]
                # 获取完整元数据
                try:
                    full_meta = await provider.get_song_metadata(best_match.id)
                    return source_name, {
                        "lyrics": full_meta.get("lyrics") if full_meta else None,
                        "cover_url": full_meta.get("cover_url") if full_meta else best_match.cover_url,
                        "album": full_meta.get("album") if full_meta else best_match.album,
                        "publish_time": full_meta.get("publish_time") if full_meta else best_match.publish_time,
                        "search_result": best_match
                    }
                except Exception:
                    return source_name, {
                        "lyrics": None,
                        "cover_url": best_match.cover_url,
                        "album": best_match.album,
                        "publish_time": best_match.publish_time,
                        "search_result": best_match
                    }
        except Exception as e:
            logger.warning(f"从 {source_name} 搜索失败: {e}")
        return source_name, None
    
    # 并发执行
    tasks = [search_provider(name, provider) for name, provider in providers]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    source_data = {}
    for result in results:
        if isinstance(result, Exception):
            continue
        name, data = result
        if data:
            source_data[name] = data
    
    # 聚合结果（保持原有逻辑）
    result = MetadataResult()
    
    # 优先网易云歌词
    if "netease" in source_data and source_data["netease"].get("lyrics"):
        result.lyrics = source_data["netease"]["lyrics"]
        result.source = "netease"
        result.search_result = source_data["netease"].get("search_result")
    elif "qqmusic" in source_data and source_data["qqmusic"].get("lyrics"):
        result.lyrics = source_data["qqmusic"]["lyrics"]
        result.source = "qqmusic"
        result.search_result = source_data["qqmusic"].get("search_result")
    
    # 优先QQ音乐封面和专辑
    if "qqmusic" in source_data:
        qq_data = source_data["qqmusic"]
        if qq_data.get("cover_url"):
            result.cover_url = qq_data["cover_url"]
        if qq_data.get("album"):
            result.album = qq_data["album"]
        if qq_data.get("publish_time"):
            result.publish_time = qq_data["publish_time"]
        if not result.search_result:
            result.search_result = qq_data.get("search_result")
    
    # 网易云补全
    if "netease" in source_data:
        ne_data = source_data["netease"]
        if not result.cover_url and ne_data.get("cover_url"):
            result.cover_url = ne_data["cover_url"]
        if not result.album and ne_data.get("album"):
            result.album = ne_data["album"]
        if not result.publish_time and ne_data.get("publish_time"):
            result.publish_time = ne_data["publish_time"]
    
    # 获取封面大小
    if result.cover_url:
        try:
            cover_data = await self.fetch_cover_data(result.cover_url)
            if cover_data:
                result.cover_data = cover_data
                result.cover_size_bytes = len(cover_data)
        except Exception as e:
            logger.warning(f"获取封面大小失败: {e}")
    
    result.success = bool(result.lyrics or result.cover_url or result.album)
    logger.info(f"✅ 搜索完成: lyrics={bool(result.lyrics)}, cover={bool(result.cover_url)}, album={result.album}")
    
    return result
```

### 3. 增加智能监控和告警

#### 实现补全成功率监控
```python
class MetadataEnrichmentMonitor:
    """元数据补全监控器"""
    
    def __init__(self):
        self.stats = {
            'total_attempts': 0,
            'success_count': 0,
            'failure_count': 0,
            'failure_details': {}
        }
    
    async def record_attempt(self, song_title: str, success: bool, error_msg: str = None):
        """记录补全尝试结果"""
        self.stats['total_attempts'] += 1
        
        if success:
            self.stats['success_count'] += 1
        else:
            self.stats['failure_count'] += 1
            # 记录失败详情
            if error_msg:
                error_type = self._classify_error(error_msg)
                if error_type not in self.stats['failure_details']:
                    self.stats['failure_details'][error_type] = 0
                self.stats['failure_details'][error_type] += 1
        
        # 定期输出统计信息
        if self.stats['total_attempts'] % 50 == 0:
            await self._log_stats()
    
    def _classify_error(self, error_msg: str) -> str:
        """错误分类"""
        if 'timeout' in error_msg.lower():
            return 'timeout'
        elif 'rate limit' in error_msg.lower() or '429' in error_msg:
            return 'rate_limit'
        elif 'network' in error_msg.lower():
            return 'network_error'
        elif 'api' in error_msg.lower():
            return 'api_error'
        else:
            return 'other'
    
    async def _log_stats(self):
        """输出统计信息"""
        success_rate = (self.stats['success_count'] / self.stats['total_attempts']) * 100
        logger.info(f"📊 元数据补全统计 - 总尝试: {self.stats['total_attempts']}, "
                   f"成功: {self.stats['success_count']}, "
                   f"失败: {self.stats['failure_count']}, "
                   f"成功率: {success_rate:.1f}%")
        
        if self.stats['failure_details']:
            logger.info("❌ 失败类型统计:")
            for error_type, count in self.stats['failure_details'].items():
                percentage = (count / self.stats['failure_count']) * 100
                logger.info(f"  {error_type}: {count} ({percentage:.1f}%)")

# 全局监控实例
enrichment_monitor = MetadataEnrichmentMonitor()
```

#### 在关键位置集成监控
```python
# 在 heal_song 方法中集成监控
async def heal_song(self, song_id: str, force: bool = False) -> bool:
    async with AsyncSessionLocal() as db:
        song = await db.get(Song, song_id, options=[selectinload(Song.artist), selectinload(Song.sources)])
        if not song: 
            await enrichment_monitor.record_attempt("unknown", False, "Song not found")
            return False

        try:
            success = await self._do_heal_song_logic(song, db, force)
            await enrichment_monitor.record_attempt(song.title, success)
            return success
        except Exception as e:
            await enrichment_monitor.record_attempt(song.title, False, str(e))
            raise
```

### 4. 实现失败歌曲优先处理

#### 创建失败队列管理
```python
class FailedSongsQueue:
    """失败歌曲队列管理器"""
    
    def __init__(self):
        self.failed_songs = {}  # song_id -> {'count': int, 'last_attempt': datetime}
        self.priority_queue = []  # 按失败次数和时间排序的歌曲ID
    
    async def add_failed_song(self, song_id: str):
        """添加失败歌曲到队列"""
        now = datetime.now()
        
        if song_id in self.failed_songs:
            self.failed_songs[song_id]['count'] += 1
            self.failed_songs[song_id]['last_attempt'] = now
        else:
            self.failed_songs[song_id] = {
                'count': 1,
                'last_attempt': now
            }
        
        # 重新排序优先级队列
        await self._rebuild_priority_queue()
    
    async def get_next_priority_song(self) -> Optional[str]:
        """获取下一个优先处理的歌曲ID"""
        if not self.priority_queue:
            return None
        
        # 检查是否过了最小重试间隔
        song_id = self.priority_queue[0]
        song_info = self.failed_songs[song_id]
        
        min_interval = self._get_min_interval(song_info['count'])
        time_since_last = datetime.now() - song_info['last_attempt']
        
        if time_since_last.total_seconds() >= min_interval:
            return song_id
        else:
            return None
    
    def _get_min_interval(self, failure_count: int) -> int:
        """根据失败次数确定最小重试间隔（秒）"""
        if failure_count <= 2:
            return 3600  # 1小时
        elif failure_count <= 5:
            return 10800  # 3小时
        else:
            return 21600  # 6小时
    
    async def _rebuild_priority_queue(self):
        """重建优先级队列"""
        # 按失败次数降序，时间升序排列
        self.priority_queue = sorted(
            self.failed_songs.keys(),
            key=lambda sid: (
                -self.failed_songs[sid]['count'],  # 失败次数多的优先
                self.failed_songs[sid]['last_attempt']  # 较早失败的优先
            )
        )

# 全局失败队列实例
failed_songs_queue = FailedSongsQueue()
```

#### 集成到定时任务中
```python
# 修改 heal_all 方法，优先处理失败歌曲
async def heal_all(self, force: bool = False, limit: int = 50):
    logger.info(f"🚑 开始元数据治愈任务 (Limit={limit}, Force={force})")
    
    # 首先处理优先级队列中的失败歌曲
    priority_processed = 0
    while priority_processed < limit // 2:  # 处理一半的额度给优先歌曲
        song_id = await failed_songs_queue.get_next_priority_song()
        if not song_id:
            break
            
        try:
            success = await self.heal_song(song_id, force=True)  # 强制处理优先歌曲
            priority_processed += 1
            
            if success:
                # 成功后从失败队列中移除
                failed_songs_queue.failed_songs.pop(song_id, None)
                await failed_songs_queue._rebuild_priority_queue()
            else:
                # 失败则更新最后尝试时间
                if song_id in failed_songs_queue.failed_songs:
                    failed_songs_queue.failed_songs[song_id]['last_attempt'] = datetime.now()
        except Exception as e:
            logger.error(f"处理优先歌曲失败 {song_id}: {e}")
            continue
    
    # 剩余额度用于常规扫描
    remaining_limit = limit - priority_processed
    if remaining_limit > 0:
        # ... 现有的常规扫描逻辑 ...
        pass
```

## 部署和验证计划

### 部署步骤
1. **第一阶段**（立即）：部署冷却期优化和基础监控
2. **第二阶段**（1周内）：部署增强搜索策略和重试机制
3. **第三阶段**（2周内）：部署失败队列和优先处理机制

### 验证指标
- **成功率提升**：目标将自动补全成功率从当前水平提升至85%以上
- **平均处理时间**：减少因冷却期导致的处理延迟
- **用户满意度**：减少用户需要手动干预的情况

### 监控告警
- 设置成功率低于80%时的告警
- 监控API调用失败率趋势
- 跟踪不同类型错误的发生频率

通过以上综合改进措施，应该能够显著提升自动元数据补全的成功率，缩小与手动刮削操作的差距。