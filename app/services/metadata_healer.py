# -*- coding: utf-8 -*-
"""
MetadataHealer - å…ƒæ•°æ®æ²»æ„ˆè€…

å‰èº«: EnrichmentService
åŠŸèƒ½å‡çº§:
1. æ°¸ä¹…æ²»æ„ˆ: å¯¹ä¸å®Œæ•´çš„æ­Œæ›²æŒç»­é‡è¯• (æ— å†·å´æœŸé™åˆ¶)
2. å¼ºåŠ›æœç´¢: æ”¯æŒæ–‡ä»¶åæœç´¢é™çº§
3. ç»Ÿä¸€å†™å…¥: æ¥ç®¡æ‰€æœ‰å…ƒæ•°æ®å†™å…¥ (TagService)

æ›´æ–°æ—¥å¿—:
- 2026-02-10: ç§»é™¤å…ƒæ•°æ®è¡¥å…¨å†·å´æœŸé™åˆ¶ï¼Œç½‘æ˜“äº‘å’ŒQQéŸ³ä¹æ¥å£æ— éœ€å†·å´

Author: ali
Created: 2026-02-05
"""
import logging
import os
import re
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Tuple
from sqlalchemy import select
from sqlalchemy.orm import selectinload
from core.database import AsyncSessionLocal
from app.models.song import Song
from app.services.smart_merger import SmartMerger, SongMetadata
from app.services.metadata_service import MetadataService
from app.services.tag_service import TagService

logger = logging.getLogger(__name__)

class MetadataHealer:
    """
    å…ƒæ•°æ®æ²»æ„ˆè€…
    è´Ÿè´£æ‰«æå¹¶ä¿®å¤èµ„æ–™åº“ä¸­å…ƒæ•°æ®ç¼ºå¤±çš„æ­Œæ›²
    """
    
    def __init__(self):
        self.metadata_service = MetadataService()
        
        # é…ç½®ä¸Šä¼ è·¯å¾„
        if os.path.exists("/config"):
            self.upload_root = "/config/uploads"
        else:
            self.upload_root = os.path.join(os.getcwd(), "uploads")
        self.cover_dir = os.path.join(self.upload_root, "covers")
        self.avatar_dir = os.path.join(self.upload_root, "avatars")
        os.makedirs(self.cover_dir, exist_ok=True)
        os.makedirs(self.avatar_dir, exist_ok=True)
        self.api_base_url = "https://music-api.gdstudio.xyz/api.php" # Fallback if proxy fails
        
    async def heal_all(self, force: bool = False, limit: int = 50):
        """
        å…¨åº“æ²»æ„ˆä»»åŠ¡
        
        Args:
            force: æ˜¯å¦å¼ºåˆ¶å¿½ç•¥å†·å´æœŸ (æ‰‹åŠ¨è§¦å‘æ—¶ç”¨ True)
            limit: å•æ¬¡æ‰¹å¤„ç†ä¸Šé™
        """
        logger.info(f"ğŸš‘ å¼€å§‹å…ƒæ•°æ®æ²»æ„ˆä»»åŠ¡ (Limit={limit}, Force={force})")
        
        async with AsyncSessionLocal() as db:
            # æŸ¥æ‰¾æ‰€æœ‰æœ¬åœ°æ­Œæ›²
            # è¿™é‡Œçš„ "æœ¬åœ°" æ„å‘³ç€æœ‰ local_pathï¼ŒçŠ¶æ€å¯èƒ½æ˜¯ DOWNLOADED
            stmt = select(Song).options(
                selectinload(Song.sources), 
                selectinload(Song.artist)
            ).where(Song.local_path.isnot(None)).limit(limit * 2) # å–å¤šä¸€ç‚¹ä¾›ç­›é€‰
            
            songs = (await db.execute(stmt)).scalars().all()
            
            # TaskMonitor Start
            from app.services.task_monitor import task_monitor, TaskCancelledException
            task_id = await task_monitor.start_task("heal", "æ­£åœ¨åˆå§‹åŒ–å…ƒæ•°æ®æ²»æ„ˆ...")
            
            total_candidates = len(songs)
            logger.info(f"ğŸš‘ æ‰¾åˆ° {total_candidates} é¦–å¾…æ£€æŸ¥æ­Œæ›²")
            
            healed_count = 0
            processed_so_far = 0
            
            try:
                for song in songs:
                    if healed_count >= limit:
                        break
                    
                    # Check for Pause/Cancel
                    await task_monitor.check_status(task_id)

                    processed_so_far += 1
                    
                    # Update Progress
                    pct = int((processed_so_far / total_candidates) * 100)
                    await task_monitor.update_progress(
                        task_id,
                        pct,
                        f"æ­£åœ¨æ£€æŸ¥: {song.title}",
                        details={"healed": healed_count, "total": total_candidates}
                    )
                    
                    # ğŸ”§ å…³é”®ä¿®å¤: åœ¨æ£€æŸ¥å®Œæ•´æ€§ä¹‹å‰ï¼Œå…ˆåŒæ­¥æ–‡ä»¶æ ‡ç­¾åˆ° data_json
                    # è¿™æ ·å³ä½¿æ­Œæ›²åœ¨å†·å´æœŸï¼Œä¹Ÿèƒ½ä»æ–‡ä»¶è·å–æ­Œè¯å¹¶é¿å…é‡å¤è¡¥å…¨
                    if song.local_path and os.path.exists(song.local_path):
                        try:
                            file_tags = await TagService.read_tags(song.local_path)
                            file_lyrics = file_tags.get("lyrics") if file_tags else None
                            
                            if file_lyrics:
                                # æ£€æŸ¥ data_json ä¸­æ˜¯å¦å·²æœ‰æ­Œè¯
                                has_lyrics_in_db = False
                                for src in song.sources:
                                    data = self._parse_data_json(src.data_json)
                                    if data.get("lyrics"):
                                        has_lyrics_in_db = True
                                        break
                                
                                # å¦‚æœæ–‡ä»¶æœ‰æ­Œè¯ä½† DB æ²¡æœ‰ï¼Œç«‹å³åŒæ­¥
                                if not has_lyrics_in_db:
                                    logger.info(f"ğŸ“¥ å‘ç°æ–‡ä»¶æ ‡ç­¾æ­Œè¯ï¼ŒåŒæ­¥åˆ°æ•°æ®åº“: {song.title}")
                                    if not song.sources:
                                        # å¦‚æœæ²¡æœ‰ sourceï¼Œåˆ›å»ºä¸€ä¸ª
                                        from app.models.song import SongSource
                                        new_src = SongSource(song_id=song.id, source="local", data_json={})
                                        db.add(new_src)
                                        await db.flush()
                                        song.sources.append(new_src)
                                    
                                    for src in song.sources:
                                        data = self._parse_data_json(src.data_json)
                                        data["lyrics"] = file_lyrics
                                        src.data_json = data
                                        from sqlalchemy.orm.attributes import flag_modified
                                        flag_modified(src, "data_json")
                                    
                                    # æ›´æ–°è¡¥å…¨æ—¶é—´ï¼Œæ ‡è®°ä¸ºå·²å¤„ç†
                                    song.last_enrich_at = datetime.now()
                                    await db.commit()
                                    logger.info(f"âœ… æ­Œè¯åŒæ­¥å®Œæˆ: {song.title}")
                                    healed_count += 1
                                    continue  # åŒæ­¥å®Œæˆï¼Œè·³åˆ°ä¸‹ä¸€é¦–
                        except Exception as e:
                            logger.warning(f"âš ï¸ åŒæ­¥æ–‡ä»¶æ ‡ç­¾å¤±è´¥ [{song.title}]: {e}")
                        
                    # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦æ²»æ„ˆ (ä¸å®Œæ•´)
                    if not self._is_complete(song):
                        # 2. å…ƒæ•°æ®è¡¥å…¨æ— éœ€å†·å´æœŸæ£€æŸ¥
                        # ç½‘æ˜“äº‘å’ŒQQéŸ³ä¹æ¥å£æ²¡æœ‰é¢‘ç‡é™åˆ¶ï¼Œå¯éšæ—¶è°ƒç”¨
                        
                        # 3. æ‰§è¡Œæ²»æ„ˆ
                        try:
                            success = await self.heal_song(song.id, force=force)
                            if success:
                                healed_count += 1
                                # Update details on success
                                await task_monitor.update_progress(
                                    task_id, pct, f"å·²ä¿®å¤: {song.title}", details={"healed": healed_count}
                                )
                        except Exception as e:
                            logger.error(f"âŒ æ²»æ„ˆå¤±è´¥ [{song.title}]: {e}")
                
                msg = f"æ²»æ„ˆå®Œæˆ, æˆåŠŸä¿®å¤ {healed_count} é¦–"
                logger.info(f"âœ… {msg}")
                
                await task_monitor.finish_task(task_id, msg, details={"healed": healed_count, "processed": processed_so_far})
                return healed_count
            
            except TaskCancelledException as e:
                logger.warning(f"Heal task cancelled: {e}")
                await task_monitor.finish_task(task_id, f"æ²»æ„ˆå·²å–æ¶ˆ (å·²ä¿®å¤: {healed_count})", details={"healed": healed_count})
                return healed_count

            except Exception as e:
                logger.error(f"Heal task failed: {e}")
                await task_monitor.error_task(task_id, str(e))
                return healed_count

    async def heal_song(self, song_id: str, force: bool = False) -> bool:
        """
        æ²»æ„ˆå•é¦–æ­Œæ›² (æ ¸å¿ƒé€»è¾‘)
        """
        async with AsyncSessionLocal() as db:
            song = await db.get(Song, song_id, options=[selectinload(Song.artist), selectinload(Song.sources)])
            if not song: 
                logger.error(f"âŒ æ— æ³•æ‰¾åˆ°æ­Œæ›² ID: {song_id}")
                return False

            logger.info(f"ğŸ©¹ æ­£åœ¨æ²»æ„ˆ: {song.title} (ID: {song.id})")
            
            # è®°å½•è¯¦ç»†çš„å¤„ç†ä¿¡æ¯
            processing_info = {
                'song_id': song_id,
                'title': song.title,
                'artist': song.artist.name if song.artist else "æœªçŸ¥",
                'local_path': song.local_path,
                'current_state': {
                    'has_lyrics': any(self._parse_data_json(src.data_json).get("lyrics") for src in song.sources),
                    'has_cover': bool(song.cover and song.cover.startswith("/uploads/")),
                    'has_album': bool(song.album),
                    'has_publish_time': bool(song.publish_time)
                }
            }
            
            logger.info(f"ğŸ“‹ å¤„ç†å‰çŠ¶æ€: {processing_info}")

            # --- é˜¶æ®µ 1: æœç´¢å…ƒæ•°æ® ---
            # ç­–ç•¥ A: æ ‡å‡†æœç´¢ (Title Artist)
            # ç”¨æˆ·è¦æ±‚ä¸è¦è°ƒç”¨ gdstudio è¿”å›çš„å…ƒæ•°æ®ï¼Œæˆ‘ä»¬çš„ metadata_service å·²ç»é»˜è®¤ä½¿ç”¨ç½‘æ˜“äº‘/QQ
            try:
                best_meta = await self.metadata_service.get_best_match_metadata(song.title, song.artist.name if song.artist else "")
                
                if not best_meta.success:
                    # è®°å½•å¤±è´¥è¯¦æƒ…
                    logger.warning(f"âš ï¸ å…ƒæ•°æ®æœç´¢å¤±è´¥: {song.title}")
                    logger.debug(f"ğŸ” æœç´¢è¯¦æƒ… - æ ‡é¢˜: '{song.title}', è‰ºäºº: '{song.artist.name if song.artist else ''}'")
                    logger.debug(f"ğŸ“Š æœç´¢ç»“æœ - æ­Œè¯: {bool(best_meta.lyrics)}, å°é¢: {bool(best_meta.cover_url)}, ä¸“è¾‘: {best_meta.album}")
                    
                    # ç­–ç•¥ B: æ–‡ä»¶åé™çº§æœç´¢ (å¦‚æœæ˜¯è‡ªåŠ¨å¯¼å…¥çš„ä¹±ç æ­Œæ›²)
                    if song.local_path:
                        filename_clean = self._clean_filename(song.local_path)
                        if filename_clean and filename_clean != song.title:
                            logger.info(f"ğŸ”„ æ ‡å‡†æœç´¢å¤±è´¥, å°è¯•æ–‡ä»¶åé™çº§æœç´¢: '{filename_clean}'")
                            best_meta = await self.metadata_service.get_best_match_metadata(filename_clean, "")
                            
                            if not best_meta.success:
                                logger.warning(f"âŒ æ–‡ä»¶åæœç´¢ä¹Ÿå¤±è´¥: {filename_clean}")
                                logger.debug(f"ğŸ“Š æ–‡ä»¶åæœç´¢ç»“æœ - æ­Œè¯: {bool(best_meta.lyrics)}, å°é¢: {bool(best_meta.cover_url)}, ä¸“è¾‘: {best_meta.album}")
                
                if not best_meta.success:
                    logger.error(f"âŒ æ— æ³•æ‰¾åˆ°å…ƒæ•°æ®: {song.title}")
                    # æ›´æ–°é‡è¯•æ—¶é—´
                    song.last_enrich_at = datetime.now()
                    await db.commit()
                    return False
                    
            except Exception as search_error:
                logger.error(f"ğŸ’¥ å…ƒæ•°æ®æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {song.title} - {str(search_error)}")
                logger.exception(search_error)  # è®°å½•å®Œæ•´å †æ ˆ
                song.last_enrich_at = datetime.now()
                await db.commit()
                return False

            # --- é˜¶æ®µ 2: æ™ºèƒ½åˆå¹¶ ---
            # ä¿®æ­£: ä» sources ä¸­è·å–æ­Œè¯
            current_lyrics = None
            for src in song.sources:
                data = self._parse_data_json(src.data_json)
                if data.get("lyrics"):
                    current_lyrics = data["lyrics"]
                    break

            current = SongMetadata(
                title=song.title,
                artist=song.artist.name if song.artist else "",
                album=song.album,
                cover_url=song.cover,
                lyrics=current_lyrics, 
                publish_time=song.publish_time
            )
            
            # (è¡¥å……: æ£€æŸ¥ Song æ¨¡å‹æ˜¯å¦æœ‰ lyrics å­—æ®µï¼Œä¹‹å‰çš„ä»£ç å¥½åƒéƒ½åœ¨ SongSource.data_json é‡Œå­˜ lyrics ?)
            # æ£€æŸ¥ scraper.py å‘ç° song.lyrics å¯èƒ½ä¸å­˜åœ¨äº Song æ¨¡å‹, 
            # ä½†ç”¨æˆ·æƒ³æŠŠ lyrics å†™åˆ°æ–‡ä»¶ã€‚DB å­˜å“ªé‡Œï¼Ÿ
            # æš‚æ—¶å‡è®¾ Song æ¨¡å‹æœ‰ lyrics æˆ–è€…æˆ‘ä»¬åªå…³å¿ƒå†™æ–‡ä»¶å’Œå†™ data_jsonã€‚
            # æŸ¥çœ‹ scaper.py: `if new_lyrics: song.lyrics = new_lyrics` -> çœ‹æ¥ Song æ¨¡å‹å¯èƒ½è¢«ä¿®æ”¹è¿‡æˆ–åŠ¨æ€æ·»åŠ ï¼Ÿ
            # ç¡®è®¤æ¨¡å‹å®šä¹‰: app/models/song.py åªæœ‰ `data_json` åœ¨ SongSourceã€‚
            # Song ç±»æ²¡æœ‰ lyrics å­—æ®µã€‚ scaper.py å¯èƒ½æ˜¯é”™çš„ï¼Œæˆ–è€…åŠ¨æ€å±æ€§ã€‚
            # æˆ‘ä»¬è¿™é‡Œéµå¾ª "Data in SongSource, Display in Song"
            # ä½† Song æ²¡æœ‰ lyricsã€‚æ‰€ä»¥æˆ‘ä»¬æŠŠ lyrics å­˜å“ªé‡Œï¼Ÿ -> SongSource.data_json
            
            new_meta = SongMetadata(
                title=best_meta.search_result.title if best_meta.search_result else song.title,
                artist=best_meta.search_result.artist if best_meta.search_result else "",
                album=best_meta.album,
                cover_url=best_meta.cover_url,
                lyrics=best_meta.lyrics,
                publish_time=self._parse_date(best_meta.publish_time)
            )
            
            updates = SmartMerger.merge(current, new_meta)
            
            if not updates and not force:
                logger.info("â© å…ƒæ•°æ®æœªå‘ç”Ÿæ˜¾è‘—å˜åŒ–ï¼Œè·³è¿‡")
                song.last_enrich_at = datetime.now()
                await db.commit()
                return True # è™½ç„¶æ²¡æ›´ï¼Œä½†ä¹Ÿç®—å¤„ç†å®Œ

            # --- é˜¶æ®µ 3: æ‰§è¡Œæ›´æ–° ---
            
            # 3.1 ä¸‹è½½å°é¢
            cover_data = None
            
            # ç¡®å®šæ˜¯å¦éœ€è¦ä¸‹è½½/å¤„ç†å°é¢
            # é€»è¾‘ï¼š
            # 1. updates é‡Œæœ‰æ–°å°é¢ (SmartMerger å†³å®šæ›´æ–°)
            # 2. å½“å‰å°é¢æ˜¯åœ¨çº¿é“¾æ¥ (httpå¼€å¤´) -> å§‹ç»ˆæœ¬åœ°åŒ–ï¼Œä»¥æ»¡è¶³â€œå…¨éƒ¨ç‰©ç†åµŒå…¥â€è¦æ±‚
            need_download_cover = "cover" in updates
            if not need_download_cover and song.cover and (song.cover.startswith("http") or song.cover.startswith("/api/discovery/cover")):
                need_download_cover = True
                # è¿™é‡Œä¸éœ€è¦å¼ºåˆ¶åŠ å…¥ updates["cover"]ï¼Œä¸‹é¢é€»è¾‘ä¼šç›´æ¥æ‹¿ song.cover
            
            if need_download_cover:
                cover_url = updates.get("cover") or song.cover
                # å¤„ç†ä»£ç† URL: /api/discovery/cover?source=xxx&id=yyy
                if cover_url.startswith("/api/discovery/cover"):
                    import urllib.parse as urlparse
                    parsed = urlparse.urlparse(cover_url)
                    qs = urlparse.parse_qs(parsed.query)
                    source = qs.get("source", [""])[0]
                    target_id = qs.get("id", [""])[0]
                    if source and target_id:
                        # è¿˜åŸä¸º GDStudio çš„çœŸå® pic é“¾æ¥ (å®é™…ä¸Š pic ä¼šè¿”å› jsonï¼Œæ‰€ä»¥æˆ‘ä»¬ç›´æ¥ç”¨é‚£ä¸ª pic æ¥å£)
                        cover_url = f"{self.api_base_url}?types=pic&source={source}&id={target_id}"

                web_url, local_path = await self._download_cover(cover_url)
                if web_url:
                     song.cover = web_url # è¿™ä¸€æ­¥å¾ˆå…³é”®ï¼Œå°†åœ¨çº¿é“¾æ¥æ”¹ä¸ºæœ¬åœ° /uploads é“¾æ¥
                     # è¯»å– bytes ç”¨äºå†™ tag
                     if local_path and os.path.exists(local_path):
                         with open(local_path, "rb") as f:
                             cover_data = f.read()
            elif song.cover and song.cover.startswith("/uploads/"):
                 # å·²ç»æ˜¯æœ¬åœ°å°é¢ï¼Œè¯»å–å‡ºæ¥
                 # ä¿®å¤ Windows ä¸‹çš„è·¯å¾„æ‹¼æ¥é€»è¾‘
                 rel_path = song.cover.replace("/", os.sep).lstrip(os.sep)
                 # å¦‚æœ cover æ˜¯ /uploads/covers/xxx.jpgï¼Œrel_path å˜æˆ uploads\covers\xxx.jpg
                 # è€Œ self.upload_root å¯èƒ½æ˜¯ D:\code\music-monitor\uploads
                 # æ‰€ä»¥è¦å°å¿ƒæ‹¼æ¥ã€‚ song.cover åŒ…å« 'uploads' å—ï¼Ÿ
                 # æŸ¥çœ‹ _download_cover: web_url = f"/uploads/covers/{filename}"
                 # æ‰€ä»¥ rel_path åŒ…å« uploads/covers/...
                 # æˆ‘ä»¬éœ€è¦çš„æ˜¯ç›¸å¯¹äº cwd çš„è·¯å¾„ã€‚
                 local_path = os.path.join(os.getcwd(), rel_path)
                 if os.path.exists(local_path):
                     with open(local_path, "rb") as f:
                         cover_data = f.read()

            # 3.2 æ›´æ–° DB å­—æ®µ
            if "title" in updates: song.title = updates["title"]
            if "album" in updates: song.album = updates["album"]
            if "publish_time" in updates: song.publish_time = updates["publish_time"]
            
            # 3.3 å†™å…¥æ–‡ä»¶ (TagService)
            # å‡†å¤‡å†™å…¥çš„æ•°æ®
            # ç¡®ä¿å³ä½¿è¿™æ¬¡æ²¡è·å–åˆ°æ­Œè¯ï¼Œä¹Ÿè¦å°è¯•ä»æ•°æ®åº“ç°æœ‰è®°å½•é‡Œæ‹¿ï¼Œé˜²æ­¢è¢«ç©ºå€¼è¦†ç›–
            final_lyrics = updates.get("lyrics") or new_meta.lyrics or current_lyrics
            
            tag_meta = {
                "title": song.title,
                "artist": song.artist.name if song.artist else "",
                "album": song.album,
                "date": song.publish_time,
                "lyrics": final_lyrics,
                "cover_data": cover_data
            }
            
            # æ¸…ç† None å€¼
            tag_meta = {k: v for k, v in tag_meta.items() if v is not None}

            if song.local_path and os.path.exists(song.local_path):
                success = await TagService.write_tags(song.local_path, tag_meta)
                if success:
                    logger.info(f"ğŸ’¾ æ–‡ä»¶æ ‡ç­¾å›å†™æˆåŠŸ: {song.local_path}")
            
            # 3.4 æ›´æ–° Source æ•°æ® (lyrics å’Œ cover å­˜è¿™é‡Œ)
            # ğŸ”§ ä¿®å¤: å¦‚æœæ²¡æœ‰ source è®°å½•ï¼Œåˆ›å»ºä¸€ä¸ª local source
            if not song.sources:
                from app.models.song import SongSource
                logger.info(f"âš ï¸ æ­Œæ›²æ²¡æœ‰ source è®°å½•ï¼Œåˆ›å»º local source: {song.title}")
                new_source = SongSource(
                    song_id=song.id,
                    source="local",
                    source_id=song.local_path or str(song.id),
                    data_json={"lyrics": final_lyrics} if final_lyrics else {}
                )
                db.add(new_source)
                # ç«‹å³åˆ·æ–°ä»¥è·å–æ–°åˆ›å»ºçš„ source
                await db.flush()
                song.sources.append(new_source)
            
            for src in song.sources:
                data = self._parse_data_json(src.data_json)
                changed = False
                
                # åŒæ­¥æ­Œè¯ - ç¡®ä¿æ­Œè¯ä¸€å®šå†™å…¥ data_json (ä¿®å¤æŒä¹…åŒ–é—®é¢˜)
                # ä¸è®º SmartMerger æ˜¯å¦å†³å®š"æ›´æ–°"ï¼Œåªè¦æœ‰æ­Œè¯å°±å†™å…¥
                if final_lyrics and not data.get("lyrics"):
                    data["lyrics"] = final_lyrics
                    changed = True
                elif updates.get("lyrics"):  # SmartMerger å†³å®šå‡çº§æ­Œè¯ (å¦‚ çº¯æ–‡æœ¬->LRC)
                    data["lyrics"] = updates["lyrics"]
                    changed = True
                
                # åŒæ­¥ä¸“è¾‘
                if "album" in updates:
                    data["album"] = updates["album"]
                    changed = True
                
                # åŒæ­¥å°é¢ (å¦‚æœå·²æœ¬åœ°åŒ–ï¼Œå¼ºåˆ¶æ‰€æœ‰æ¥æºåŒæ­¥)
                if song.cover and song.cover.startswith("/uploads/"):
                    if src.cover != song.cover:
                        src.cover = song.cover
                        changed = True
                    
                    # ç¡®ä¿ data_json é‡Œçš„å°é¢ä¹Ÿæ›´æ–°
                    if isinstance(data, dict):
                        if data.get("cover") != song.cover:
                            data["cover"] = song.cover
                            changed = True
                
                if changed:
                    src.data_json = data
                    # ğŸ”§ å…³é”®ä¿®å¤: SQLAlchemy ä¸ä¼šè‡ªåŠ¨è¿½è¸ª JSON å­—æ®µçš„å†…éƒ¨ä¿®æ”¹
                    # å¿…é¡»æ˜¾å¼æ ‡è®°å­—æ®µå·²å˜æ›´ï¼Œå¦åˆ™ commit æ—¶ä¸ä¼šæŒä¹…åŒ–
                    from sqlalchemy.orm.attributes import flag_modified
                    flag_modified(src, "data_json")
                    logger.info(f"ğŸ“ å·²æ›´æ–° source[{src.source}].data_json: lyrics={bool(data.get('lyrics'))}")
            
            # è°ƒè¯•: ç¡®è®¤æœ€ç»ˆçŠ¶æ€
            final_check = False
            for src in song.sources:
                d = self._parse_data_json(src.data_json)
                if d.get("lyrics"):
                    final_check = True
                    break
            logger.info(f"ğŸ” æŒä¹…åŒ–æ£€æŸ¥: {song.title} æ­Œè¯å·²ä¿å­˜={final_check}, sourcesæ•°é‡={len(song.sources)}")
            
            await db.commit()
            return True

    async def heal_artist(self, db, artist) -> bool:
        """æ²»æ„ˆæ­Œæ‰‹å¤´åƒ (æœ¬åœ°åŒ–)"""
        if not artist.avatar or not artist.avatar.startswith("http"):
            return False
            
        logger.info(f"ğŸ¨ æ­£åœ¨æœ¬åœ°åŒ–æ­Œæ‰‹å¤´åƒ: {artist.name}")
        web_url, local_path = await self._download_image(artist.avatar, "avatars")
        
        if web_url:
            artist.avatar = web_url
            # åŒæ­¥åˆ°æ‰€æœ‰ source
            for src in artist.sources:
                src.avatar = web_url
            
            await db.commit()
            logger.info(f"âœ… æ­Œæ‰‹å¤´åƒæœ¬åœ°åŒ–æˆåŠŸ: {artist.name} -> {web_url}")
            return True
        return False

    def _is_complete(self, song: Song) -> bool:
        """
        æ£€æŸ¥æ­Œæ›²å…ƒæ•°æ®æ˜¯å¦å®Œæ•´ (ä¸¥æ ¼æ¨¡å¼: 6 å­—æ®µå…¨è¦†ç›–)
        
        å¿…é¡»åŒæ—¶æ»¡è¶³:
        1. title - æ­Œåéç©º
        2. artist - æ­Œæ‰‹éç©º
        3. album - ä¸“è¾‘åéç©º
        4. cover - å°é¢å·²æœ¬åœ°åŒ– (/uploads/ å¼€å¤´)
        5. publish_time - å‘å¸ƒæ—¥æœŸéç©º
        6. lyrics - æ­Œè¯éç©º (å­˜å‚¨åœ¨ SongSource.data_json)
        """
        # 1. æ ¸å¿ƒå­—æ®µ (Song æ¨¡å‹)
        has_title = bool(song.title and song.title.strip())
        has_artist = bool(song.artist and song.artist.name)
        has_album = bool(song.album and song.album.strip())
        has_cover = bool(song.cover and song.cover.startswith("/uploads/"))  # å¿…é¡»æ˜¯æœ¬åœ°åŒ–å°é¢
        has_publish_time = bool(song.publish_time)
        
        # 2. æ­Œè¯ (åœ¨ SongSource.data_json é‡Œ)
        has_lyrics = False
        for src in song.sources:
            data = self._parse_data_json(src.data_json)
            if data.get("lyrics"):
                has_lyrics = True
                break
        
        # è°ƒè¯•æ—¥å¿—: æ˜¾ç¤ºå“ªäº›å­—æ®µç¼ºå¤±
        is_complete = all([has_title, has_artist, has_album, has_cover, has_publish_time, has_lyrics])
        if not is_complete:
            missing = []
            if not has_title: missing.append("title")
            if not has_artist: missing.append("artist")
            if not has_album: missing.append("album")
            if not has_cover: missing.append(f"cover({song.cover})")
            if not has_publish_time: missing.append("publish_time")
            if not has_lyrics: missing.append("lyrics")
            logger.info(f"âŒ æ­Œæ›²ä¸å®Œæ•´ [{song.title}]: ç¼ºå°‘ {', '.join(missing)}")
        
        return is_complete

    def _should_skip_enrichment(self, song: Song) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡å…ƒæ•°æ®è¡¥å…¨
        å…ƒæ•°æ®è·å–ä½¿ç”¨ç½‘æ˜“äº‘å’ŒQQéŸ³ä¹æ¥å£ï¼Œæ— éœ€å†·å´æœŸé™åˆ¶
        """
        # å…ƒæ•°æ®è¡¥å…¨æ“ä½œèµ„æºæ¶ˆè€—å¾ˆå°ï¼Œå¯éšæ—¶æ‰§è¡Œ
        return False

    def _clean_filename(self, path: str) -> Optional[str]:
        """æ¸…æ´—æ–‡ä»¶åç”¨äºæœç´¢"""
        if not path: return None
        base = os.path.basename(path)
        name_no_ext = os.path.splitext(base)[0]
        
        # ç§»é™¤å¸¸è§çš„åˆ†éš”ç¬¦å’Œæ•°å­—
        # e.g. "01. Song Name" -> "Song Name"
        # "Song_Name_HQ" -> "Song Name"
        
        cleaned = re.sub(r'^\d+[\.\s\-]+', '', name_no_ext) # å»å¤´æ•°å­—
        cleaned = cleaned.replace("_", " ")
        cleaned = re.sub(r'\s*\(.*?\)', '', cleaned) # å»æ‹¬å·å†…å®¹ (HQ) ç­‰
        return cleaned.strip()

    def _parse_data_json(self, data_json) -> Dict:
        if isinstance(data_json, dict): return data_json
        return {}

    def _parse_date(self, val):
        """è§£ææ—¥æœŸ (æ”¯æŒå¤šç§æ ¼å¼)"""
        if not val: return None
        if isinstance(val, datetime): return val
        
        if isinstance(val, str):
            val = val.strip()
            try:
                # 2023-01-01
                if "-" in val and len(val) >= 10:
                     return datetime.strptime(val[:10], "%Y-%m-%d")
                # 2023
                if len(val) == 4 and val.isdigit():
                     return datetime.strptime(val, "%Y")
                # 1672531200000 (Timestamp)
                if val.isdigit() and len(val) > 8:
                     ts = int(val)
                     if len(val) > 10: ts = ts / 1000
                     return datetime.fromtimestamp(ts)
            except:
                pass
        return None

    async def _download_cover(self, url: str) -> Tuple[Optional[str], Optional[str]]:
        """ä¸‹è½½å°é¢ (å…¼å®¹æ—§è°ƒç”¨)"""
        return await self._download_image(url, "covers")

    async def _download_image(self, url: str, folder: str = "covers") -> Tuple[Optional[str], Optional[str]]:
        """ä¸‹è½½å›¾ç‰‡å¹¶ä¿å­˜åˆ°æŒ‡å®šç›®å½•"""
        try:
            import hashlib
            import aiohttp
            ext = "png" if ".png" in url.lower() else "jpg"
            md5 = hashlib.md5(url.encode()).hexdigest()
            filename = f"{md5}.{ext}"
            
            target_dir = os.path.join(self.upload_root, folder)
            os.makedirs(target_dir, exist_ok=True)
            
            save_path = os.path.join(target_dir, filename)
            web_url = f"/uploads/{folder}/{filename}"
            
            if os.path.exists(save_path):
                return web_url, save_path
                
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=15) as resp:
                    if resp.status == 200:
                        content = await resp.read()
                        
                        # ç‰¹æ®Šå¤„ç†: GDStudio çš„ pic é“¾æ¥å¯èƒ½è¿”å› JSON {"url": "..."}
                        if b'{"url":' in content[:100]:
                            import json
                            try:
                                data = json.loads(content.decode("utf-8"))
                                img_real_url = data.get("url")
                                if img_real_url:
                                    return await self._download_image(img_real_url, folder)
                            except:
                                pass
                        
                        with open(save_path, "wb") as f:
                            f.write(content)
                        return web_url, save_path
            return None, None
        except Exception as e:
            logger.warning(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ ({url}): {e}")
            return None, None

    async def _download_cover_legacy(self, url: str) -> Tuple[Optional[str], Optional[str]]:
        try:
            import hashlib
            import aiohttp
            ext = "png" if ".png" in url.lower() else "jpg"
            md5 = hashlib.md5(url.encode()).hexdigest()
            filename = f"{md5}.{ext}"
            save_path = os.path.join(self.cover_dir, filename)
            web_url = f"/uploads/covers/{filename}"
            
            if os.path.exists(save_path):
                return web_url, save_path
                
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=15) as resp:
                    if resp.status == 200:
                        content = await resp.read()
                        
                        # ç‰¹æ®Šå¤„ç†: GDStudio çš„ pic é“¾æ¥å¯èƒ½è¿”å› JSON {"url": "..."}
                        # æˆ‘ä»¬çš„ _download_cover å¦‚æœæ”¶åˆ°çš„æ˜¯è¿™ç§ JSONï¼Œéœ€è¦è§£æåå†ä¸‹è½½å›¾ç‰‡
                        if b'{"url":' in content[:100]:
                            import json
                            try:
                                data = json.loads(content.decode("utf-8"))
                                img_real_url = data.get("url")
                                if img_real_url:
                                    # é‡æ–°è¯·æ±‚å›¾ç‰‡
                                    return await self._download_cover(img_real_url)
                            except:
                                pass

                        with open(save_path, "wb") as f:
                            f.write(content)
                        return web_url, save_path
            return None, None
        except Exception as e:
            logger.warning(f"å°é¢ä¸‹è½½å¤±è´¥: {e}")
            return None, None
