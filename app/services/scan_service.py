# -*- coding: utf-8 -*-
"""
ScanService - æœ¬åœ°åª’ä½“åº“æ–‡ä»¶æ‰«ææœåŠ¡

åŠŸèƒ½ï¼š
- æ‰«ææœ¬åœ°éŸ³é¢‘æ–‡ä»¶ç›®å½• (audio_cache, favorites)
- å‘ç°æœªå…¥åº“çš„æ­Œæ›²å¹¶æ·»åŠ åˆ°æ•°æ®åº“
- æ¸…ç†æ•°æ®åº“ä¸­ç‰©ç†æ–‡ä»¶å·²ä¸å­˜åœ¨çš„"æ­»é”®"
- æ”¯æŒå¢é‡æ‰«ææ¨¡å¼
- æä¾›æ‰«æè¿›åº¦å›è°ƒ

Author: google
Created: 2026-01-30
"""
from typing import Optional, Callable, Dict
from sqlalchemy.ext.asyncio import AsyncSession
import os
from datetime import datetime
from pathlib import Path
import anyio
import logging

from app.repositories.song import SongRepository
from app.repositories.artist import ArtistRepository
from app.models.song import Song, SongSource
from sqlalchemy import select, delete
import hashlib
import binascii  # For manual APIC parsing if needed, though mutagen usually handles it

logger = logging.getLogger(__name__)


class ScanService:
    """æœ¬åœ°åª’ä½“åº“æ–‡ä»¶æ‰«ææœåŠ¡"""
    
    def __init__(self):
        self.supported_extensions = ('.mp3', '.flac', '.m4a', '.wav')
        self.scan_directories = ["audio_cache", "favorites"]
    
    @staticmethod
    def _normalize_cn_brackets(text: str) -> str:
        """
        å½’ä¸€åŒ–ä¸­æ–‡æ‹¬å·ä¸ºè‹±æ–‡æ‹¬å·ï¼Œå¹¶ç§»é™¤æ‰€æœ‰ç©ºæ ¼ä»¥æœ€å¤§åŒ–åŒ¹é…å®¹é”™ç‡
        
        Args:
            text: å¾…å½’ä¸€åŒ–çš„æ–‡æœ¬
            
        Returns:
            å½’ä¸€åŒ–åçš„æ–‡æœ¬
        """
        if not text:
            return ""
        text = text.replace('ï¼ˆ', '(').replace('ï¼‰', ')')
        text = text.replace('ã€', '[').replace('ã€‘', ']')
        # ç§»é™¤æ‰€æœ‰ç©ºæ ¼ä»¥å®ç°ä¸¥æ ¼çš„æ¨¡ç³ŠåŒ¹é…
        return text.replace(" ", "").strip()
    
    async def scan_local_files(
        self,
        db: AsyncSession,
        progress_callback: Optional[Callable[[Dict], None]] = None,
        incremental: bool = False
    ) -> Dict[str, int]:
        """
        å…¨é‡/å¢é‡æ‰«ææœ¬åœ°éŸ³é¢‘æ–‡ä»¶ç›®å½•ã€‚
        
        è¯¥æ–¹æ³•è´Ÿè´£å‘ç°ç‰©ç†ç£ç›˜ä¸Šå­˜åœ¨ä½†æ•°æ®åº“ä¸­ç¼ºå¤±çš„æ­Œæ›²ï¼Œå¹¶è¿›è¡Œâ€œå…¥åº“â€æ“ä½œã€‚
        å®ƒä¼šè‡ªåŠ¨æå–éŸ³é¢‘æ–‡ä»¶çš„å†…åµŒæ ‡ç­¾ï¼ˆå°é¢ã€æ­Œæ‰‹ã€æ ‡é¢˜ã€éŸ³è´¨ï¼‰ã€‚
        
        ä¼˜åŒ–ç‚¹:
        - é¢„åŠ è½½æ‰€æœ‰ç°æœ‰çš„æœ¬åœ°æº IDï¼Œé¿å… N+1 æŸ¥è¯¢ã€‚
        - ç¼“å­˜æ‰€æœ‰æ­Œæ‰‹ä¿¡æ¯ï¼Œå‡å°‘é‡å¤çš„æ­Œæ‰‹æŸ¥è¯¢/åˆ›å»ºã€‚
        - å»¶è¿Ÿæäº¤ (Bulk Commit)ï¼Œæ˜¾è‘—æå‡æ•°åƒä¸ªæ–‡ä»¶æ—¶çš„æ‰«ææ€§èƒ½ã€‚
        
        Args:
            db (AsyncSession): å¼‚æ­¥æ•°æ®åº“ä¼šè¯ã€‚
            progress_callback (Callable): ç”¨äºå®æ—¶æ¨é€æ‰«æè¿›åº¦çš„å›è°ƒå‡½æ•°ã€‚
            incremental (bool): è‹¥ä¸º Trueï¼Œåˆ™è·³è¿‡æ¸…ç†é˜¶æ®µï¼ˆPruningï¼‰ï¼Œä»…æ‰«ææ–°æ–‡ä»¶ã€‚
            
        Returns:
            Dict[str, int]: åŒ…å«ç»“æœç»Ÿè®¡çš„å­—å…¸:
                {
                    "new_files_found": int, # æ–°å¢å…¥åº“æ•°é‡
                    "removed_files_count": int # æ¸…ç†å¤±æ•ˆè®°å½•æ•°é‡
                }
        """
        from mutagen import File as MutagenFile
        from app.models.artist import Artist
        
        new_count = 0
        removed_count = 0
        
        song_repo = SongRepository(db)
        
        # --- é˜¶æ®µ 1: æ¸…ç†é˜¶æ®µ (Pruning) ---
        if not incremental:
            removed_count = await self._prune_missing_files(db, progress_callback)
        
        # è·å–æ‰€æœ‰ç°æœ‰çš„æœ¬åœ°æº ID
        stmt = select(SongSource.source_id).where(SongSource.source == "local")
        existing_source_ids = set((await db.execute(stmt)).scalars().all())
        logger.info(f"ğŸ“Š æ•°æ®åº“ä¸­å·²å­˜åœ¨ {len(existing_source_ids)} ä¸ªæœ¬åœ°æ–‡ä»¶è®°å½•")

        # ç¼“å­˜æ‰€æœ‰æ­Œæ‰‹ä¿¡æ¯ä»¥å‡å°‘æŸ¥è¯¢
        all_artists = (await db.execute(select(Artist))).scalars().all()
        artist_map = {a.name: a for a in all_artists}
        
        # --- é˜¶æ®µ 2: æ‰«æé˜¶æ®µ (Scanning) ---
        for dir_name in self.scan_directories:
            exists = await anyio.to_thread.run_sync(os.path.exists, dir_name)
            if not exists:
                logger.debug(f"ç›®å½•ä¸å­˜åœ¨,è·³è¿‡: {dir_name}")
                continue
            
            files = await anyio.to_thread.run_sync(os.listdir, dir_name)
            audio_files = [f for f in files if f.endswith(self.supported_extensions)]
            total_files = len(audio_files)
            processed_files = 0
            
            for filename in audio_files:
                processed_files += 1
                
                # è¿›åº¦å›è°ƒ
                if progress_callback:
                    progress_callback({
                        "stage": "scanning",
                        "directory": dir_name,
                        "current": processed_files,
                        "total": total_files,
                        "filename": filename
                    })
                
                file_path = os.path.join(dir_name, filename).replace("\\", "/")
                
                # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡ (å†…å­˜ä¸­æ£€æŸ¥)
                if filename in existing_source_ids:
                    # å¦‚æœéœ€è¦æ›´æ–°éŸ³è´¨ï¼Œå¯ä»¥åœ¨è¿™é‡ŒåŠ é€»è¾‘ï¼Œä½†é€šå¸¸æ‰«æä¸éœ€è¦åœ¨è¿™é‡Œé¢‘ç¹æ›´æ–°
                    continue
                
                # å‘ç°æ–°æ–‡ä»¶
                logger.info(f"ğŸ“‚ å‘ç°æ–°æœ¬åœ°æ–‡ä»¶: {file_path}")
                metadata = await self._extract_metadata(file_path, filename)
                
                # è·å–æ­Œæ‰‹ (ä½¿ç”¨ç¼“å­˜)
                artist_name = metadata['artist_name']
                if artist_name in artist_map:
                    artist_obj = artist_map[artist_name]
                else:
                    artist_repo = ArtistRepository(db)
                    artist_obj = await artist_repo.get_or_create_by_name(artist_name)
                    artist_map[artist_name] = artist_obj
                
                # æŸ¥æ‰¾æˆ–åˆ›å»ºæ­Œæ›²
                song_obj = await self._find_or_create_song(
                    db, song_repo, metadata, artist_obj
                )
                
                # åˆ›å»ºæœ¬åœ°æºè®°å½•
                data_json = {
                    "quality": metadata.get('quality_info', 'PQ'),
                    "format": os.path.splitext(filename)[1].replace('.', '').upper(),
                    "cover": metadata.get('cover')
                }
                
                new_source = SongSource(
                    song_id=song_obj.id,
                    source="local",
                    source_id=filename,
                    url=file_path,
                    data_json=data_json,
                    cover=data_json.get('cover')
                )
                db.add(new_source)
                existing_source_ids.add(filename)
                new_count += 1
                
                # æ¯ 50 ä¸ªæ–‡ä»¶ flush ä¸€æ¬¡ï¼Œé˜²æ­¢äº‹åŠ¡è¿‡å¤§
                if new_count % 50 == 0:
                    await db.flush()

        # ç»Ÿä¸€æäº¤
        if new_count > 0:
            await db.commit()
            logger.info(f"ğŸ’¾ æ‰«æå®Œæˆ,å·²å…¥åº“ {new_count} ä¸ªæ–°æ–‡ä»¶")
        
        # æœ€ç»ˆè¿›åº¦å›è°ƒ
        if progress_callback:
            progress_callback({
                "stage": "completed",
                "new_files_found": new_count,
                "removed_files_count": removed_count
            })
        
        return {
            "new_files_found": new_count,
            "removed_files_count": removed_count
        }
    
    async def _prune_missing_files(
        self,
        db: AsyncSession,
        progress_callback: Optional[Callable[[Dict], None]] = None
    ) -> int:
        """
        æ¸…ç†â€œæ­»é”®â€ï¼šç§»é™¤æ•°æ®åº“ä¸­å­˜åœ¨ä½†ç‰©ç†ç£ç›˜æ–‡ä»¶å·²ä¸¢å¤±çš„è®°å½•ã€‚
        
        å¦‚æœä¸€é¦–æ­Œæ›²ä»…æœ‰è¯¥æœ¬åœ°æºä¸”æ–‡ä»¶ä¸¢å¤±ï¼Œåˆ™ä¼šè¿åŒæ­Œæ›²è®°å½•ä¸€èµ·åˆ é™¤ï¼›
        å¦‚æœè¯¥æ­Œæ›²è¿˜æœ‰å…¶ä»–åœ¨çº¿æºï¼Œåˆ™ä»…æ¸…é™¤æœ¬åœ°è·¯å¾„å¹¶é‡ç½®çŠ¶æ€ä¸º PENDINGã€‚
        
        Args:
            db (AsyncSession): æ•°æ®åº“ä¼šè¯ã€‚
            progress_callback (Callable): è¿›åº¦å›è°ƒã€‚
            
        Returns:
            int: è¢«æ¸…ç†æˆ–ä¿®æ­£çš„è®°å½•ç»Ÿè®¡ã€‚
        """
        removed_count = 0
        
        # æŸ¥æ‰¾æ‰€æœ‰æ ‡è®°ä¸ºæœ¬åœ°å·²ä¸‹è½½çš„æ­Œæ›²
        stmt = select(Song).where(Song.local_path.isnot(None))
        res = await db.execute(stmt)
        all_local_songs = res.scalars().all()
        
        total_songs = len(all_local_songs)
        
        for idx, song in enumerate(all_local_songs, 1):
            # è¿›åº¦å›è°ƒ
            if progress_callback:
                progress_callback({
                    "stage": "pruning",
                    "current": idx,
                    "total": total_songs,
                    "song_title": song.title
                })
            
            # æ ¡éªŒç‰©ç†æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            exists = await anyio.to_thread.run_sync(os.path.exists, song.local_path)
            if not exists:
                logger.info(f"ğŸ—‘ï¸ å‘ç°å¤±æ•ˆæœ¬åœ°æ–‡ä»¶è®°å½•,æ­£åœ¨æ¸…ç†: {song.title} ({song.local_path})")
                
                # 1. ç§»é™¤æœ¬åœ°æºä¿¡æ¯
                source_del_stmt = delete(SongSource).where(
                    SongSource.song_id == song.id,
                    SongSource.source == "local"
                )
                await db.execute(source_del_stmt)
                await db.flush()  # å¿…é¡»å³æ—¶åˆ·æ–°ï¼Œå¦åˆ™ä¸‹æ–¹çš„æŸ¥è¯¢ä¼šåŒ…å«å·²åˆ é™¤çš„æº
                
                # 2. æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å…¶ä»–åœ¨çº¿æº
                source_count_stmt = select(SongSource).where(SongSource.song_id == song.id)
                sources = (await db.execute(source_count_stmt)).scalars().all()
                
                if not sources:
                    # å½»åº•å­¤ç«‹çš„æ­Œæ›²è®°å½•,ç›´æ¥åˆ é™¤
                    await db.delete(song)
                else:
                    # ä»ç„¶æœ‰åœ¨çº¿ç›‘æ§,åªæ˜¯æœ¬åœ°æ–‡ä»¶ä¸¢äº†,é‡ç½®çŠ¶æ€
                    song.local_path = None
                    song.status = "PENDING"
                
                removed_count += 1
        
        if removed_count > 0:
            await db.commit()
            logger.info(f"âœ… æˆåŠŸæ¸…ç†äº† {removed_count} æ¡å¤±æ•ˆæœ¬åœ°è®°å½•")
            
        return removed_count
    
    async def _extract_metadata(self, file_path: str, filename: str) -> Dict[str, any]:
        """
        ä»éŸ³é¢‘æ–‡ä»¶ä¸­æå–å…ƒæ•°æ®
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            filename: æ–‡ä»¶å
            
        Returns:
            å…ƒæ•°æ®å­—å…¸ { title, artist_name, album, publish_time }
        """
        from mutagen import File as MutagenFile
        
        title = None
        artist_name = "Unknown"
        album = None
        publish_time = None
        cover_url = None
        
        try:
            audio_file = MutagenFile(file_path, easy=False)
            if audio_file is not None:
                # æå–å°é¢
                try:
                    cover_data = None
                    # ID3 (MP3)
                    if hasattr(audio_file, 'tags') and hasattr(audio_file.tags, 'getall'):
                        apic_frames = audio_file.tags.getall('APIC')
                        if apic_frames:
                            cover_data = apic_frames[0].data
                    
                    # FLAC / Vorbis
                    if not cover_data and hasattr(audio_file, 'pictures'):
                        if audio_file.pictures:
                            cover_data = audio_file.pictures[0].data
                            
                    # M4A (MP4)
                    if not cover_data and hasattr(audio_file, 'tags') and 'covr' in audio_file.tags:
                        covrs = audio_file.tags['covr']
                        if covrs:
                            cover_data = covrs[0] # bytes

                    if cover_data:
                        # Save to /uploads/covers/
                        md5 = hashlib.md5(cover_data).hexdigest()
                        
                        # Determine Log/Config dir (Hack: assume relative or env)
                        # We use relative path 'uploads' based on main.py logic matching
                        # Better to read global config but for now relative 'uploads' works if CWD is consistent
                        upload_root = "uploads"
                        if os.path.exists("/config"): # Docker env
                             upload_root = "/config/uploads"
                        
                        cover_dir = os.path.join(upload_root, "covers")
                        os.makedirs(cover_dir, exist_ok=True)
                        
                        cover_filename = f"{md5}.jpg" # Assume jpg for simplicity or detect magic
                        # Simple magic check
                        if cover_data.startswith(b'\x89PNG'): cover_filename = f"{md5}.png"
                        
                        save_path = os.path.join(cover_dir, cover_filename)
                        if not os.path.exists(save_path):
                            with open(save_path, "wb") as f:
                                f.write(cover_data)
                        
                        cover_url = f"/uploads/covers/{cover_filename}"
                        
                except Exception as e:
                    logger.warning(f"å°é¢æå–å¤±è´¥ {filename}: {e}")

                # æå–åŸºæœ¬ä¿¡æ¯
                # æå–åŸºæœ¬ä¿¡æ¯
                if 'title' in audio_file:
                    title = audio_file['title'][0]
                if 'artist' in audio_file:
                    artist_name = audio_file['artist'][0]
                if 'album' in audio_file:
                    album = audio_file['album'][0]
                
                # æå–æ—¥æœŸ
                date_str = None
                if 'date' in audio_file:
                    date_str = audio_file['date'][0]
                elif 'TDRC' in audio_file:
                    date_str = str(audio_file['TDRC'])
                elif 'TYER' in audio_file:
                    date_str = str(audio_file['TYER'])
                
                if date_str:
                    try:
                        # æå–å‰4ä½æ•°å­—ä½œä¸ºå¹´ä»½
                        year_str = str(date_str)[:4]
                        if year_str.isdigit():
                            publish_time = datetime.strptime(year_str, "%Y")
                    except:
                        pass
        except Exception as e:
            logger.warning(f"âŒ è¯»å–æ ‡ç­¾å¤±è´¥ {filename}: {e}")
        
        # æ–‡ä»¶åå›é€€ç­–ç•¥
        clean_name = os.path.splitext(filename)[0]
        if not title:
            if " - " in clean_name:
                parts = clean_name.split(" - ", 1)
                artist_name = parts[0].strip()
                title = parts[1].strip()
            else:
                title = clean_name.strip()
        
        return {
            "title": title,
            "artist_name": artist_name,
            "album": album,
            "publish_time": publish_time,
            "cover": cover_url,
            "quality_info": self._analyze_quality(audio_file)
        }

    def _analyze_quality(self, audio_file) -> str:
        """
        ä¼˜é›…çš„éŸ³è´¨åˆ¤å®šé€»è¾‘ (Elegant Quality Logic):
        
        ä¼˜å…ˆçº§ (Priority):
        1. HI-RES (HR): é‡‡æ ·ç‡ > 48kHz æˆ– ä½æ·± > 16bit (æ— è®ºæ ¼å¼)
        2. LOSSLESS (SQ): æ— æŸç¼–ç æ ¼å¼ (FLAC/WAV/ALAC/APE) ä¸”é HR
        3. HIGH QUALITY (HQ): æœ‰æŸæ ¼å¼ (MP3/AAC/OGG) ä¸”æ¯”ç‰¹ç‡ >= 320kbps (å®½æ¾å¤„ç† >= 250k)
        4. STANDARD (PQ): å…¶ä»–æƒ…å†µ
        """
        try:
            if not audio_file or not hasattr(audio_file, 'info'):
                return "PQ"
            
            info = audio_file.info
            
            # --- 1. è·å–åŸºç¡€éŸ³é¢‘å‚æ•° ---
            sample_rate = getattr(info, 'sample_rate', 0) or 0
            bitrate = getattr(info, 'bitrate', 0) or 0
            bits_per_sample = getattr(info, 'bits_per_sample', 0) or 0 # FLAC/WAV/ALAC usually have this
            
            # --- 2. åˆ¤å®š Hi-Res (HR) ---
            # å®šä¹‰: è¶…è¿‡ CD ç”»è´¨æ ‡å‡† (44.1kHz/16bit)
            # åªè¦é‡‡æ ·ç‡ > 48k (å¦‚ 96k, 192k) æˆ–è€… ä½æ·± > 16 (å¦‚ 24bit) å³è§†ä¸º HR
            # æ³¨æ„: 48kHz 16bit é€šå¸¸ä¹Ÿè¢«è§†ä¸ºå¸¸è§„æ— æŸ(SQ)ï¼Œåªæœ‰ > 48k æ‰ç®— HR
            if sample_rate > 48000 or bits_per_sample > 16:
                return "HR"
            
            # --- 3. åˆ¤å®šæ— æŸ (SQ) ---
            # æ£€æŸ¥æ–‡ä»¶å®¹å™¨/ç¼–ç æ ¼å¼
            # Mutagen ç±»åé€šå¸¸åŒ…å«æ ¼å¼ä¿¡æ¯ï¼Œå¦‚ 'mutagen.flac.FLAC', 'mutagen.wave.WAVE'
            file_type = type(audio_file).__name__.lower()
            mime = getattr(audio_file, 'mime', [])
            
            is_lossless_format = (
                'flac' in file_type or 
                'wave' in file_type or 
                'alac' in file_type or
                'monkeysaudio' in file_type or # APE
                'aiff' in file_type
            )
            
            # ä¹Ÿå¯ä»¥é€šè¿‡ mime åˆ¤æ–­
            if not is_lossless_format and mime:
                for m in mime:
                    if 'flac' in m or 'wav' in m:
                        is_lossless_format = True
                        break
            
            if is_lossless_format:
                return "SQ"
                
            # --- 4. åˆ¤å®šé«˜å“è´¨æœ‰æŸ (HQ) ---
            # å¯¹äº MP3/AAC/OGG
            # 320kbps MP3 (â‰ˆ320000 bps)
            # AAC 256kbps å®é™…ä¸ŠéŸ³è´¨æ¥è¿‘/ä¼˜äº 320k MP3ï¼Œè¿™é‡Œæ”¾å®½é˜ˆå€¼åˆ° 256k (250000)
            if bitrate >= 250000:
                return "HQ"
                
            # --- 5. æ ‡å‡†éŸ³è´¨ (PQ) ---
            # 128kbps, 192kbps ç­‰
            return "PQ"
            
        except Exception as e:
            logger.warning(f"Quality analysis error: {e}")
            return "PQ"
    
    async def _find_or_create_song(
        self,
        db: AsyncSession,
        song_repo: SongRepository,
        metadata: Dict[str, any],
        artist_obj
    ) -> Song:
        """
        æŸ¥æ‰¾æˆ–åˆ›å»ºæ­Œæ›²è®°å½• (æ”¯æŒå¢å¼ºæ¨¡ç³ŠåŒ¹é…)
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            song_repo: æ­Œæ›²ä»“åº“
            metadata: å…ƒæ•°æ®
            artist_obj: æ­Œæ‰‹å¯¹è±¡
            
        Returns:
            æ­Œæ›²å¯¹è±¡
        """
        title = metadata['title']
        album = metadata['album']
        publish_time = metadata['publish_time']
        
        cover = metadata.get('cover')

        # ç²¾ç¡®åŒ¹é…
        song_obj = await song_repo.get_by_title_artist(title, artist_obj.id)
        
        if not song_obj:
            # å°è¯•å½’ä¸€åŒ–åŒ¹é… (è§£å†³ "Title (Live)" vs "Title(Live)")
            all_artist_songs = await song_repo.get_by_artist(artist_obj.id)
            norm_local_title = self._normalize_cn_brackets(title).lower().strip()
            
            for existing in all_artist_songs:
                norm_db_title = self._normalize_cn_brackets(existing.title).lower().strip()
                if norm_local_title == norm_db_title:
                    song_obj = existing
                    logger.info(f"  ğŸ”— æ¨¡ç³ŠåŒ¹é…æˆåŠŸ: '{title}' -> '{existing.title}'")
                    break
        
        if not song_obj:
            # åˆ›å»ºæ–°æ­Œæ›²
            song_obj = Song(
                title=title,
                album=album,
                artist_id=artist_obj.id,
                status="DOWNLOADED",  # æœ¬åœ°æ–‡ä»¶å·²å­˜åœ¨
                local_path=None,  # ç¨åè®¾ç½®
                created_at=datetime.now(),
                publish_time=publish_time,
                cover=cover
            )
            db.add(song_obj)
            await db.flush()  # è·å– ID
        else:
            # æ›´æ–°ç°æœ‰è®°å½•
            if not song_obj.album and album:
                song_obj.album = album
            # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°é«˜æ¸…å°é¢ (å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶æ‰«æï¼Œè¯´æ˜ç”¨æˆ·å¸Œæœ›ä»¥æ­¤ä¸ºå‡†)
            if cover:
                 # Check if current cover is already local to avoid churn? 
                 # But cover filename is hash of content, so it's stable.
                 song_obj.cover = cover
                 
            song_obj.status = "DOWNLOADED"
        
        return song_obj
    
    async def _create_song_source(
        self,
        db: AsyncSession,
        song_obj: Song,
        filename: str,
        file_path: str,
        data_json: Dict = None
    ):
        """
        åˆ›å»ºæ­Œæ›²æºè®°å½•
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            song_obj: æ­Œæ›²å¯¹è±¡
            filename: æ–‡ä»¶å
            file_path: æ–‡ä»¶è·¯å¾„
            data_json: é¢å¤–æ•°æ®
        """
        # æ›´æ–°æ­Œæ›²çš„æœ¬åœ°è·¯å¾„
        if not song_obj.local_path:
            song_obj.local_path = file_path
        
        # æ£€æŸ¥è¯¥ç‰¹å®šçš„æœ¬åœ°æ–‡ä»¶æºæ˜¯å¦å·²å­˜åœ¨
        stmt = select(SongSource).where(
            SongSource.song_id == song_obj.id,
            SongSource.source == "local",
            SongSource.source_id == filename
        )
        existing_source = (await db.execute(stmt)).scalar_one_or_none()
        
        if existing_source:
            # å¦‚æœå­˜åœ¨ï¼Œæ›´æ–° data_json (ä¸ºäº†ä¿®å¤æ—§æ•°æ®)
            if data_json:
                existing_source.data_json = data_json
                existing_source.url = file_path # ç¡®ä¿è·¯å¾„ä¹Ÿæ˜¯æœ€æ–°çš„
        else:
            # åˆ›å»ºæœ¬åœ°æºè®°å½•
            new_source = SongSource(
                song_id=song_obj.id,
                source="local",
                source_id=filename,
                url=file_path,
                data_json=data_json,
                cover=data_json.get('cover') if data_json else None
            )
            db.add(new_source)
