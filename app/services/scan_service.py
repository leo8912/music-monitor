# -*- coding: utf-8 -*-
"""
ScanService - æœ¬åœ°åª’ä½“åº“æ–‡ä»¶æ‰«ææœåŠ¡

åŠŸèƒ½ï¼š
- æ‰«ææœ¬åœ°éŸ³é¢‘æ–‡ä»¶ç›®å½• (audio_cache, favorites)
- å‘ç°æœªå…¥åº“çš„æ­Œæ›²å¹¶æ·»åŠ åˆ°æ•°æ®åº“
- æ¸…ç†æ•°æ®åº“ä¸­ç‰©ç†æ–‡ä»¶å·²ä¸å­˜åœ¨çš„"æ­»é”®"
- æ”¯æŒå¢é‡æ‰«ææ¨¡å¼
- æä¾›æ‰«æè¿›åº¦å›è°ƒ

Author: google
Created: 2026-01-30
"""
from typing import Optional, Callable, Dict
from sqlalchemy.ext.asyncio import AsyncSession
import os
from datetime import datetime
from pathlib import Path
import anyio
import logging

from app.repositories.song import SongRepository
from app.repositories.artist import ArtistRepository
from app.models.song import Song, SongSource
from sqlalchemy import select, delete
import hashlib
import binascii  # For manual APIC parsing if needed, though mutagen usually handles it

logger = logging.getLogger(__name__)


class ScanService:
    """æœ¬åœ°åª’ä½“åº“æ–‡ä»¶æ‰«ææœåŠ¡"""
    
    def __init__(self):
        from core.config_manager import get_config_manager
        
        storage_cfg = get_config_manager().get("storage", {})
        
        # Collect all configured paths
        paths = set()
        
        # 1. Cache Dir (ä¸´æ—¶/æ¨é€)
        cache_dir = storage_cfg.get("cache_dir", "audio_cache")
        if cache_dir:
            paths.add(cache_dir)
        
        # 2. Favorites Dir (æ”¶è—)
        favorites_dir = storage_cfg.get("favorites_dir", "favorites")
        if favorites_dir:
            paths.add(favorites_dir)
            
        # 3. Library Dir (é™æ€èµ„æ–™åº“)
        # æ³¨æ„: å³ä½¿ config æ²¡é…ï¼Œä¹Ÿä¸è¦éšæ„ fallback åˆ° "media"ï¼Œé™¤éæ˜ç¡®æŒ‡å®š
        library_dir = storage_cfg.get("library_dir")
        if library_dir:
             paths.add(library_dir)
        
        # Filter out empty strings and normalize
        self.scan_directories = [p for p in paths if p and isinstance(p, str)]
        logger.info(f"ğŸ”§ ScanService initialized with allowed paths: {self.scan_directories}")
        
        self.supported_extensions = ('.mp3', '.flac', '.m4a', '.wav')
    
    @staticmethod
    def _normalize_cn_brackets(text: str) -> str:
        """
        å½’ä¸€åŒ–ä¸­æ–‡æ‹¬å·ä¸ºè‹±æ–‡æ‹¬å·ï¼Œå¹¶ç§»é™¤æ‰€æœ‰ç©ºæ ¼ä»¥æœ€å¤§åŒ–åŒ¹é…å®¹é”™ç‡
        
        Args:
            text: å¾…å½’ä¸€åŒ–çš„æ–‡æœ¬
            
        Returns:
            å½’ä¸€åŒ–åçš„æ–‡æœ¬
        """
        if not text:
            return ""
        text = text.replace('ï¼ˆ', '(').replace('ï¼‰', ')')
        text = text.replace('ã€', '[').replace('ã€‘', ']')
        # ç§»é™¤æ‰€æœ‰ç©ºæ ¼ä»¥å®ç°ä¸¥æ ¼çš„æ¨¡ç³ŠåŒ¹é…
        return text.replace(" ", "").strip()
    
    async def scan_local_files(
        self,
        db: AsyncSession,
        progress_callback: Optional[Callable[[Dict], None]] = None,
        incremental: bool = False
    ) -> Dict[str, int]:
        """
        å…¨é‡/å¢é‡æ‰«ææœ¬åœ°éŸ³é¢‘æ–‡ä»¶ç›®å½•ã€‚
        
        è¯¥æ–¹æ³•è´Ÿè´£å‘ç°ç‰©ç†ç£ç›˜ä¸Šå­˜åœ¨ä½†æ•°æ®åº“ä¸­ç¼ºå¤±çš„æ­Œæ›²ï¼Œå¹¶è¿›è¡Œâ€œå…¥åº“â€æ“ä½œã€‚
        å®ƒä¼šè‡ªåŠ¨æå–éŸ³é¢‘æ–‡ä»¶çš„å†…åµŒæ ‡ç­¾ï¼ˆå°é¢ã€æ­Œæ‰‹ã€æ ‡é¢˜ã€éŸ³è´¨ï¼‰ã€‚
        
        ä¼˜åŒ–ç‚¹:
        - é¢„åŠ è½½æ‰€æœ‰ç°æœ‰çš„æœ¬åœ°æº IDï¼Œé¿å… N+1 æŸ¥è¯¢ã€‚
        - ç¼“å­˜æ‰€æœ‰æ­Œæ‰‹ä¿¡æ¯ï¼Œå‡å°‘é‡å¤çš„æ­Œæ‰‹æŸ¥è¯¢/åˆ›å»ºã€‚
        - å»¶è¿Ÿæäº¤ (Bulk Commit)ï¼Œæ˜¾è‘—æå‡æ•°åƒä¸ªæ–‡ä»¶æ—¶çš„æ‰«ææ€§èƒ½ã€‚
        
        Args:
            db (AsyncSession): å¼‚æ­¥æ•°æ®åº“ä¼šè¯ã€‚
            progress_callback (Callable): ç”¨äºå®æ—¶æ¨é€æ‰«æè¿›åº¦çš„å›è°ƒå‡½æ•°ã€‚
            incremental (bool): è‹¥ä¸º Trueï¼Œåˆ™è·³è¿‡æ¸…ç†é˜¶æ®µï¼ˆPruningï¼‰ï¼Œä»…æ‰«ææ–°æ–‡ä»¶ã€‚
            
        Returns:
            Dict[str, int]: åŒ…å«ç»“æœç»Ÿè®¡çš„å­—å…¸:
                {
                    "new_files_found": int, # æ–°å¢å…¥åº“æ•°é‡
                    "removed_files_count": int # æ¸…ç†å¤±æ•ˆè®°å½•æ•°é‡
                }
        """
        from mutagen import File as MutagenFile
        from app.models.artist import Artist
        
        new_count = 0
        removed_count = 0
        
        song_repo = SongRepository(db)
        
        # --- é˜¶æ®µ 1: æ¸…ç†é˜¶æ®µ (Pruning) ---
        if not incremental:
            removed_count = await self._prune_missing_files(db, progress_callback)
        
        # è·å–æ‰€æœ‰ç°æœ‰çš„æœ¬åœ°æº ID
        stmt = select(SongSource.source_id).where(SongSource.source == "local")
        existing_source_ids = set((await db.execute(stmt)).scalars().all())
        logger.info(f"ğŸ“Š æ•°æ®åº“ä¸­å·²å­˜åœ¨ {len(existing_source_ids)} ä¸ªæœ¬åœ°æ–‡ä»¶è®°å½•")

        # ç¼“å­˜æ‰€æœ‰æ­Œæ‰‹ä¿¡æ¯ä»¥å‡å°‘æŸ¥è¯¢
        all_artists = (await db.execute(select(Artist))).scalars().all()
        artist_map = {a.name: a for a in all_artists}
        
        # --- é˜¶æ®µ 2: æ‰«æé˜¶æ®µ (Scanning) ---
        # --- é˜¶æ®µ 2: æ‰«æé˜¶æ®µ (Scanning) ---
        logger.info(f"ğŸ” å‡†å¤‡æ‰«æç›®å½•åˆ—è¡¨: {self.scan_directories}")
        
        for dir_name in self.scan_directories:
            abs_path = os.path.abspath(dir_name)
            exists = await anyio.to_thread.run_sync(os.path.exists, dir_name)
            
            if not exists:
                logger.warning(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨, è·³è¿‡: {dir_name} (ç»å¯¹è·¯å¾„: {abs_path})")
                continue
            
            logger.info(f"ğŸ“‚ æ­£åœ¨æ‰«æç›®å½•: {dir_name} (ç»å¯¹è·¯å¾„: {abs_path})")
            files = await anyio.to_thread.run_sync(os.listdir, dir_name)
            logger.info(f"   - ç›®å½•ä¸‹æ–‡ä»¶æ€»æ•°: {len(files)}")
            # Filter first, then process
            audio_files = [f for f in files if f.lower().endswith(self.supported_extensions)]
            total_files = len(audio_files)
            processed_files = 0
            
            for filename in audio_files:
                processed_files += 1
                
                # è¿›åº¦å›è°ƒ
                if progress_callback:
                    progress_callback({
                        "stage": "scanning",
                        "directory": dir_name,
                        "current": processed_files,
                        "total": total_files,
                        "filename": filename
                    })
                
                file_path = os.path.join(dir_name, filename).replace("\\", "/")
                
                # [Fix]: ä¸è¦ç®€å•æ ¹æ® filename è·³è¿‡ï¼Œéœ€è¦ç»“åˆè·¯å¾„åˆ¤æ–­
                # æˆ‘ä»¬å°†åœ¨ _create_song_source ä¸­å¤„ç†å…·ä½“çš„å»é‡é€»è¾‘
                # ä½†ä¸ºäº†æ€§èƒ½ï¼Œå¦‚æœæˆ‘ä»¬ç¡®å®šè¯¥æ–‡ä»¶çš„è·¯å¾„å·²ç»å®Œå…¨å…¥åº“ï¼Œå¯ä»¥è·³è¿‡
                # (TODO: éœ€è¦ä¸€ä¸ª existing_paths é›†åˆæ¥åšè¿™ç§å¿«é€Ÿè¿‡æ»¤ï¼Œç›®å‰å…ˆä¸åšä¸¥æ ¼è¿‡æ»¤ä»¥ç¡®ä¿ä¿®å¤)
                
                # å‘ç°æ½œåœ¨æ–‡ä»¶ (å¯èƒ½æ˜¯å·²å­˜åœ¨çš„)
                # logger.debug(f"ğŸ“‚ å¤„ç†æ–‡ä»¶: {file_path}")
                metadata = await self._extract_metadata(file_path, filename)
                
                # [Fix] ensure metadata is a dict
                if metadata is None:
                     metadata = {}

                # å¦‚æœæå–å¤±è´¥ï¼ˆè¿”å›ç©ºæˆ–æ— æ•ˆï¼‰ï¼Œå°è¯•ä»æ–‡ä»¶åè§£æ (Artist - Title)
                filename_no_ext = os.path.splitext(filename)[0]
                
                if not metadata.get('title'):
                    if " - " in filename_no_ext:
                        parts = filename_no_ext.split(" - ", 1)
                        metadata['artist_name'] = parts[0].strip()
                        metadata['title'] = parts[1].strip()
                    else:
                        metadata['title'] = filename_no_ext
                
                if not metadata.get('artist_name'):
                     metadata['artist_name'] = "Unknown Artist"
                     
                # Fallback: Check if title still contains " - " and artist is Unknown
                # (Handle case where title was set but artist wasn't)
                if metadata.get('artist_name') == "Unknown Artist" and " - " in metadata.get('title', ''):
                     parts = metadata['title'].split(" - ", 1)
                     metadata['artist_name'] = parts[0].strip()
                     metadata['title'] = parts[1].strip()
                     
                # Ensure other keys exist
                for key in ['album', 'cover']:
                    if key not in metadata:
                        metadata[key] = None
                
                if 'publish_time' not in metadata:
                    metadata['publish_time'] = None

                # è·å–æ­Œæ‰‹ (ä½¿ç”¨ç¼“å­˜)
                artist_name = metadata['artist_name']
                if artist_name in artist_map:
                    artist_obj = artist_map[artist_name]
                else:
                    artist_repo = ArtistRepository(db)
                    artist_obj = await artist_repo.get_or_create_by_name(artist_name)
                    artist_map[artist_name] = artist_obj
                
                # æŸ¥æ‰¾æˆ–åˆ›å»ºæ­Œæ›²
                song_obj = await self._find_or_create_song(
                    db, song_repo, metadata, artist_obj
                )
                
                # åˆ›å»ºæœ¬åœ°æºè®°å½• (ä½¿ç”¨å°è£…æ–¹æ³•å¤„ç†å»é‡å’Œ path æ›´æ–°)
                data_json = {
                    "quality": metadata.get('quality_info', 'PQ'),
                    "format": os.path.splitext(filename)[1].replace('.', '').upper(),
                    "cover": metadata.get('cover')
                }
                
                await self._create_song_source(
                    db, song_obj, filename, file_path, data_json
                )
                
                existing_source_ids.add(filename)
                new_count += 1
                
                # æ¯ 50 ä¸ªæ–‡ä»¶ flush ä¸€æ¬¡ï¼Œé˜²æ­¢äº‹åŠ¡è¿‡å¤§
                if new_count % 50 == 0:
                    await db.flush()

        # ç»Ÿä¸€æäº¤
        if new_count > 0:
            await db.commit()
            logger.info(f"ğŸ’¾ æ‰«æå®Œæˆ,å·²å…¥åº“ {new_count} ä¸ªæ–°æ–‡ä»¶")
        
        # æœ€ç»ˆè¿›åº¦å›è°ƒ
        if progress_callback:
            progress_callback({
                "stage": "completed",
                "new_files_found": new_count,
                "removed_files_count": removed_count
            })
        
        return {
            "new_files_found": new_count,
            "removed_files_count": removed_count
        }
    
    async def _prune_missing_files(
        self,
        db: AsyncSession,
        progress_callback: Optional[Callable[[Dict], None]] = None
    ) -> int:
        """
        æ¸…ç†â€œæ­»é”®â€ï¼šç§»é™¤æ•°æ®åº“ä¸­å­˜åœ¨ä½†ç‰©ç†ç£ç›˜æ–‡ä»¶å·²ä¸¢å¤±çš„è®°å½•ã€‚
        
        å¦‚æœä¸€é¦–æ­Œæ›²ä»…æœ‰è¯¥æœ¬åœ°æºä¸”æ–‡ä»¶ä¸¢å¤±ï¼Œåˆ™ä¼šè¿åŒæ­Œæ›²è®°å½•ä¸€èµ·åˆ é™¤ï¼›
        å¦‚æœè¯¥æ­Œæ›²è¿˜æœ‰å…¶ä»–åœ¨çº¿æºï¼Œåˆ™ä»…æ¸…é™¤æœ¬åœ°è·¯å¾„å¹¶é‡ç½®çŠ¶æ€ä¸º PENDINGã€‚
        
        Args:
            db (AsyncSession): æ•°æ®åº“ä¼šè¯ã€‚
            progress_callback (Callable): è¿›åº¦å›è°ƒã€‚
            
        Returns:
            int: è¢«æ¸…ç†æˆ–ä¿®æ­£çš„è®°å½•ç»Ÿè®¡ã€‚
        """
        removed_count = 0
        
        # æŸ¥æ‰¾æ‰€æœ‰æ ‡è®°ä¸ºæœ¬åœ°å·²ä¸‹è½½çš„æ­Œæ›²
        stmt = select(Song).where(Song.local_path.isnot(None))
        res = await db.execute(stmt)
        all_local_songs = res.scalars().all()
        
        total_songs = len(all_local_songs)
        
        for idx, song in enumerate(all_local_songs, 1):
            # è¿›åº¦å›è°ƒ
            if progress_callback:
                progress_callback({
                    "stage": "pruning",
                    "current": idx,
                    "total": total_songs,
                    "song_title": song.title
                })
            
            # æ ¡éªŒç‰©ç†æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            exists = await anyio.to_thread.run_sync(os.path.exists, song.local_path)
            if not exists:
                logger.info(f"ğŸ—‘ï¸ å‘ç°å¤±æ•ˆæœ¬åœ°æ–‡ä»¶è®°å½•,æ­£åœ¨æ¸…ç†: {song.title} ({song.local_path})")
                
                # 1. ç§»é™¤æœ¬åœ°æºä¿¡æ¯
                source_del_stmt = delete(SongSource).where(
                    SongSource.song_id == song.id,
                    SongSource.source == "local"
                )
                await db.execute(source_del_stmt)
                await db.flush()  # å¿…é¡»å³æ—¶åˆ·æ–°ï¼Œå¦åˆ™ä¸‹æ–¹çš„æŸ¥è¯¢ä¼šåŒ…å«å·²åˆ é™¤çš„æº
                
                # 2. æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å…¶ä»–åœ¨çº¿æº
                source_count_stmt = select(SongSource).where(SongSource.song_id == song.id)
                sources = (await db.execute(source_count_stmt)).scalars().all()
                
                if not sources:
                    # å½»åº•å­¤ç«‹çš„æ­Œæ›²è®°å½•,ç›´æ¥åˆ é™¤
                    await db.delete(song)
                else:
                    # ä»ç„¶æœ‰åœ¨çº¿ç›‘æ§,åªæ˜¯æœ¬åœ°æ–‡ä»¶ä¸¢äº†,é‡ç½®çŠ¶æ€
                    song.local_path = None
                    song.status = "PENDING"
                
                removed_count += 1
        
        if removed_count > 0:
            await db.commit()
            logger.info(f"âœ… æˆåŠŸæ¸…ç†äº† {removed_count} æ¡å¤±æ•ˆæœ¬åœ°è®°å½•")
            
        return removed_count
    
    async def _extract_metadata(self, file_path: str, filename: str) -> Dict[str, any]:
        """
        ä»éŸ³é¢‘æ–‡ä»¶ä¸­æå–å…ƒæ•°æ®
        (åŒ…å«é’ˆå¯¹æŸå MP3 çš„ ID3 é™çº§å¤„ç†)
        """
        from mutagen import File as MutagenFile
        from datetime import datetime
        import hashlib
        
        title = None
        artist_name = "Unknown"
        album = None
        publish_time = None
        cover_url = None
        quality_info = "HQ" 
        
        audio_file = None
        
        # 1. å°è¯•ä½¿ç”¨ mutagen.File è‡ªåŠ¨æ¢æµ‹
        try:
            audio_file = MutagenFile(file_path, easy=False)
        except Exception:
            pass
        
        # 2. [Fix] å¦‚æœè‡ªåŠ¨æ¢æµ‹å¤±è´¥ï¼Œä¸”æ˜¯ MP3ï¼Œå°è¯•å¼ºåˆ¶è¯»å– ID3 æ ‡ç­¾
        # è¿™å¯ä»¥è§£å†³ "can't sync to MPEG frame" å¯¼è‡´æ•´ä¸ªæ–‡ä»¶è¯»å–å¤±è´¥çš„é—®é¢˜
        if not audio_file and filename.lower().endswith('.mp3'):
             from mutagen.id3 import ID3
             try:
                 audio_file = ID3(file_path)
             except Exception:
                 pass

        if audio_file:
            # --- å°é¢æå– ---
            try:
                cover_data = None
                if hasattr(audio_file, 'tags') and audio_file.tags:
                    tags = audio_file.tags
                    # ID3 (MP3) or MP3 object with tags
                    if hasattr(tags, 'get') and (tags.get("APIC:") or tags.get("APIC")):
                        apic = tags.get("APIC:") or tags.get("APIC")
                        cover_data = apic.data
                    # FLAC or Vorbis
                    elif hasattr(audio_file, 'pictures') and audio_file.pictures:
                        cover_data = audio_file.pictures[0].data
                    # Fallback for ID3 dict iteration
                    elif isinstance(tags, dict): 
                         for key in tags.keys():
                            if key.startswith('APIC'):
                                cover_data = tags[key].data
                                break
                
                # M4A / MP4
                if not cover_data and hasattr(audio_file, 'tags') and 'covr' in audio_file.tags:
                    covrs = audio_file.tags['covr']
                    if covrs: cover_data = covrs[0]

                if cover_data:
                    # è®¡ç®—å°é¢ MD5
                    md5 = hashlib.md5(cover_data).hexdigest()
                    
                    upload_root = "uploads"
                    if os.path.exists("/config"): # Docker env
                         upload_root = "/config/uploads"
                    
                    cover_dir = os.path.join(upload_root, "covers")
                    os.makedirs(cover_dir, exist_ok=True)
                    
                    cover_filename = f"{md5}.jpg"
                    if cover_data.startswith(b'\x89PNG'): cover_filename = f"{md5}.png"
                    
                    save_path = os.path.join(cover_dir, cover_filename)
                    if not os.path.exists(save_path):
                        with open(save_path, "wb") as f:
                            f.write(cover_data)
                    
                    cover_url = f"/uploads/covers/{cover_filename}"
                    
            except Exception as e:
                pass # Squelch cover errors

            # --- åŸºæœ¬ä¿¡æ¯æå– ---
            def get_tag(obj, keys):
                for k in keys:
                    # Case 1: Dict-like (EasyID3/dict)
                    if hasattr(obj, 'get'):
                        val = obj.get(k)
                        if val:
                            if isinstance(val, list): return val[0]
                            return str(val)
                    # Case 2: ID3 Object with tags attr
                    if hasattr(obj, 'tags') and obj.tags and k in obj.tags:
                        val = obj.tags[k]
                        if hasattr(val, 'text'): return val.text[0]
                        return str(val)
                    # Case 3: obj IS tags (ID3 Object)
                    if k in obj:
                         val = obj[k]
                         if hasattr(val, 'text'): return val.text[0]
                         return str(val)
                return None

            # å°è¯•ä» tags æˆ– audio_file æœ¬èº«è·å–
            target = audio_file
            if hasattr(audio_file, 'tags') and audio_file.tags:
                target = audio_file.tags

            # Title
            t = get_tag(target, ['title', 'TIT2'])
            if t: title = t
            
            # Artist
            a = get_tag(target, ['artist', 'TPE1'])
            if a: artist_name = a
            
            # Album
            al = get_tag(target, ['album', 'TALB'])
            if al: album = al
            
            # Date
            d = get_tag(target, ['date', 'TDRC', 'TYER'])
            if d:
                date_str = str(d)
                try:
                    year_str = str(date_str)[:4]
                    if year_str.isdigit():
                        publish_time = datetime.strptime(year_str, "%Y")
                except:
                    pass
    
    
        # æ–‡ä»¶åå›é€€ç­–ç•¥
        # [Fix] å¦‚æœæ ‡é¢˜ç¼ºå¤±ï¼Œæˆ–è€…æ­Œæ‰‹æ˜¯ "Unknown" (ä¸”æ–‡ä»¶ååŒ…å« " - ")ï¼Œåˆ™å°è¯•è§£ææ–‡ä»¶å
        clean_name = os.path.splitext(filename)[0]
        should_parse_filename = not title
        
        if not should_parse_filename and (not artist_name or artist_name == "Unknown"):
             if " - " in clean_name:
                 should_parse_filename = True

        if should_parse_filename:
            if " - " in clean_name:
                parts = clean_name.split(" - ", 1)
                artist_name = parts[0].strip()
                title = parts[1].strip()
            else:
                # åªæœ‰å½“æ ‡é¢˜çœŸçš„ç¼ºå¤±æ—¶æ‰ç”¨æ–‡ä»¶åä½œä¸ºæ ‡é¢˜
                if not title:
                    title = clean_name.strip()
        
        # Quality Analysis
        quality_info = "HQ"
        if audio_file:
             try:
                # Assuming _analyze_quality is available in self
                quality_info = self._analyze_quality(audio_file)
             except:
                quality_info = "HQ"
            
        return {
            "title": title,
            "artist_name": artist_name,
            "album": album,
            "publish_time": publish_time,
            "cover_url": cover_url,
            "quality": quality_info
        }

    def _analyze_quality(self, audio_file) -> str:
        """
        ä¼˜é›…çš„éŸ³è´¨åˆ¤å®šé€»è¾‘ (Elegant Quality Logic):
        
        ä¼˜å…ˆçº§ (Priority):
        1. HI-RES (HR): é‡‡æ ·ç‡ > 48kHz æˆ– ä½æ·± > 16bit (æ— è®ºæ ¼å¼)
        2. LOSSLESS (SQ): æ— æŸç¼–ç æ ¼å¼ (FLAC/WAV/ALAC/APE) ä¸”é HR
        3. HIGH QUALITY (HQ): æœ‰æŸæ ¼å¼ (MP3/AAC/OGG) ä¸”æ¯”ç‰¹ç‡ >= 320kbps (å®½æ¾å¤„ç† >= 250k)
        4. STANDARD (PQ): å…¶ä»–æƒ…å†µ
        5. ERROR (ERR): æ–‡ä»¶æŸåæˆ–æ— æ³•è¯»å–
        """
        try:
            if not audio_file or not hasattr(audio_file, 'info'):
                return "ERR"
            
            info = audio_file.info
            
            # --- 1. è·å–åŸºç¡€éŸ³é¢‘å‚æ•° ---
            sample_rate = getattr(info, 'sample_rate', 0) or 0
            bitrate = getattr(info, 'bitrate', 0) or 0
            bits_per_sample = getattr(info, 'bits_per_sample', 0) or 0 # FLAC/WAV/ALAC usually have this
            
            # --- 2. åˆ¤å®š Hi-Res (HR) ---
            # å®šä¹‰: è¶…è¿‡ CD ç”»è´¨æ ‡å‡† (44.1kHz/16bit)
            # åªè¦é‡‡æ ·ç‡ > 48k (å¦‚ 96k, 192k) æˆ–è€… ä½æ·± > 16 (å¦‚ 24bit) å³è§†ä¸º HR
            # æ³¨æ„: 48kHz 16bit é€šå¸¸ä¹Ÿè¢«è§†ä¸ºå¸¸è§„æ— æŸ(SQ)ï¼Œåªæœ‰ > 48k æ‰ç®— HR
            if sample_rate > 48000 or bits_per_sample > 16:
                return "HR"
            
            # --- 3. åˆ¤å®šæ— æŸ (SQ) ---
            # æ£€æŸ¥æ–‡ä»¶å®¹å™¨/ç¼–ç æ ¼å¼
            # Mutagen ç±»åé€šå¸¸åŒ…å«æ ¼å¼ä¿¡æ¯ï¼Œå¦‚ 'mutagen.flac.FLAC', 'mutagen.wave.WAVE'
            file_type = type(audio_file).__name__.lower()
            mime = getattr(audio_file, 'mime', [])
            
            is_lossless_format = (
                'flac' in file_type or 
                'wave' in file_type or 
                'alac' in file_type or
                'monkeysaudio' in file_type or # APE
                'aiff' in file_type
            )
            
            # ä¹Ÿå¯ä»¥é€šè¿‡ mime åˆ¤æ–­
            if not is_lossless_format and mime:
                for m in mime:
                    if 'flac' in m or 'wav' in m:
                        is_lossless_format = True
                        break
            
            if is_lossless_format:
                return "SQ"
                
            # --- 4. åˆ¤å®šé«˜å“è´¨æœ‰æŸ (HQ) ---
            # å¯¹äº MP3/AAC/OGG
            # 320kbps MP3 (â‰ˆ320000 bps)
            # AAC 256kbps å®é™…ä¸ŠéŸ³è´¨æ¥è¿‘/ä¼˜äº 320k MP3ï¼Œè¿™é‡Œæ”¾å®½é˜ˆå€¼åˆ° 256k (250000)
            if bitrate >= 250000:
                return "HQ"
                
            # --- 5. æ ‡å‡†éŸ³è´¨ (PQ) ---
            # 128kbps, 192kbps ç­‰
            return "PQ"
            
        except Exception as e:
            logger.warning(f"Quality analysis error: {e}")
            return "PQ"
    
    async def _find_or_create_song(
        self,
        db: AsyncSession,
        song_repo: SongRepository,
        metadata: Dict[str, any],
        artist_obj
    ) -> Song:
        """
        æŸ¥æ‰¾æˆ–åˆ›å»ºæ­Œæ›²è®°å½• (æ”¯æŒå¢å¼ºæ¨¡ç³ŠåŒ¹é…)
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            song_repo: æ­Œæ›²ä»“åº“
            metadata: å…ƒæ•°æ®
            artist_obj: æ­Œæ‰‹å¯¹è±¡
            
        Returns:
            æ­Œæ›²å¯¹è±¡
        """
        title = metadata['title']
        album = metadata['album']
        publish_time = metadata['publish_time']
        
        cover = metadata.get('cover')

        # ç²¾ç¡®åŒ¹é…
        song_obj = await song_repo.get_by_title_artist(title, artist_obj.id)
        
        if not song_obj:
            # å°è¯•å½’ä¸€åŒ–åŒ¹é… (è§£å†³ "Title (Live)" vs "Title(Live)")
            all_artist_songs = await song_repo.get_by_artist(artist_obj.id)
            norm_local_title = self._normalize_cn_brackets(title).lower().strip()
            
            for existing in all_artist_songs:
                norm_db_title = self._normalize_cn_brackets(existing.title).lower().strip()
                if norm_local_title == norm_db_title:
                    song_obj = existing
                    logger.info(f"  ğŸ”— æ¨¡ç³ŠåŒ¹é…æˆåŠŸ: '{title}' -> '{existing.title}'")
                    break
        
        if not song_obj:
            # åˆ›å»ºæ–°æ­Œæ›²
            song_obj = Song(
                title=title,
                album=album,
                artist_id=artist_obj.id,
                status="DOWNLOADED",  # æœ¬åœ°æ–‡ä»¶å·²å­˜åœ¨
                local_path=None,  # ç¨åè®¾ç½®
                created_at=datetime.now(),
                publish_time=publish_time,
                cover=cover
            )
            db.add(song_obj)
            await db.flush()  # è·å– ID
        else:
            # æ›´æ–°ç°æœ‰è®°å½•
            if not song_obj.album and album:
                song_obj.album = album
            # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°é«˜æ¸…å°é¢ (å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶æ‰«æï¼Œè¯´æ˜ç”¨æˆ·å¸Œæœ›ä»¥æ­¤ä¸ºå‡†)
            if cover:
                 # Check if current cover is already local to avoid churn? 
                 # But cover filename is hash of content, so it's stable.
                 song_obj.cover = cover
                 
            song_obj.status = "DOWNLOADED"
        
        return song_obj
    
    async def _create_song_source(
        self,
        db: AsyncSession,
        song_obj: Song,
        filename: str,
        file_path: str,
        data_json: Dict = None
    ):
        """
        åˆ›å»ºæ­Œæ›²æºè®°å½• (æ”¯æŒå¤šè·¯å¾„åŒåæ–‡ä»¶)
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            song_obj: æ­Œæ›²å¯¹è±¡
            filename: æ–‡ä»¶å (ç”¨ä½œåŸºç¡€ source_id)
            file_path: æ–‡ä»¶è·¯å¾„ (url)
            data_json: é¢å¤–æ•°æ®
        """
        # æ›´æ–°æ­Œæ›²çš„æœ¬åœ°è·¯å¾„ (å¦‚æœæ˜¯é¦–ä¸ªæœ¬åœ°æºï¼Œæˆ–è€…åŸæ¥çš„è·¯å¾„å·²å¤±æ•ˆ)
        if not song_obj.local_path:
            song_obj.local_path = file_path
        
        # 1. å°è¯•æŸ¥æ‰¾å®Œå…¨åŒ¹é… (Song + Path)
        stmt_path = select(SongSource).where(
            SongSource.song_id == song_obj.id,
            SongSource.source == "local",
            SongSource.url == file_path
        )
        # Use first() to avoid crashing on duplicates (MultipleResultsFound)
        existing_by_path = (await db.execute(stmt_path)).scalars().first()
        
        if existing_by_path:
            # è·¯å¾„å®Œå…¨åŒ¹é…ï¼Œåªéœ€æ›´æ–° metadata
            if data_json:
                existing_by_path.data_json = data_json
                existing_by_path.cover = data_json.get('cover')
            return

        # 2. å¦‚æœè·¯å¾„æœªåŒ¹é…ï¼Œè¯´æ˜è¿™æ˜¯è¯¥æ­Œæ›²çš„ä¸€ä¸ªæ–°æ–‡ä»¶ (å¯èƒ½æ˜¯ duplicate at different path)
        # æˆ‘ä»¬éœ€è¦ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„ source_id
        
        # 2.1 æ£€æŸ¥æ˜¯å¦å¯ä»¥ç›´æ¥ç”¨ filename ä½œä¸º source_id
        stmt_filename = select(SongSource).where(
            SongSource.song_id == song_obj.id,
            SongSource.source == "local",
            SongSource.source_id == filename
        )
        existing_by_filename = (await db.execute(stmt_filename)).scalars().first()
        
        final_source_id = filename
        
        if existing_by_filename:
            # å†²çªï¼å·²æœ‰ä¸€ä¸ªåŒåæ–‡ä»¶ (source_id=filename)ï¼Œä½†è·¯å¾„ä¸åŒ (å‰é¢ check_path æ²¡è¿‡)
            # æˆ‘ä»¬éœ€è¦ä¸ºå½“å‰æ–‡ä»¶ç”Ÿæˆä¸€ä¸ªæ–°çš„ unique source_id
            # ç­–ç•¥: filename + "_" + MD5(path)[:6]
            path_hash = hashlib.md5(file_path.encode('utf-8')).hexdigest()[:6]
            final_source_id = f"{filename}_{path_hash}"
            logger.info(f"ğŸ”€ å‘ç°åŒåä¸åŒç›®å½•æ–‡ä»¶ï¼Œç”Ÿæˆå”¯ä¸€ID: {final_source_id}")
            
        # åˆ›å»ºæ–°çš„æºè®°å½•
        new_source = SongSource(
            song_id=song_obj.id,
            source="local",
            source_id=final_source_id, # å¯èƒ½æ˜¯ filename æˆ– filename_hash
            url=file_path,
            data_json=data_json,
            cover=data_json.get('cover') if data_json else None
        )
        db.add(new_source)
